{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWCQnbMRfjjQ"
      },
      "source": [
        "<h1><center>–î–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞: –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö</center></h1>\n",
        "\n",
        "–ê–≤—Ç–æ—Ä: –í–ª–∞–¥–∏–º–∏—Ä –ë–∞–π–∫–∞–ª–æ–≤ (Telegram: @noname_untitled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfXKc8fbfjjR"
      },
      "source": [
        "–í —ç—Ç–æ–π –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç–µ –≤—ã —Ä–µ–∞–ª–∏–∑—É–µ—Ç–µ –∏ –∏—Å—Å–ª–µ–¥—É–µ—Ç–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ª–æ–≥–æ–≤ –Ø–Ω–¥–µ–∫—Å –ú—É–∑—ã–∫–∏ [\"Yambda\"](https://huggingface.co/datasets/yandex/yambda) –≤—ã:\n",
        "\n",
        "1) –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n",
        "2) –†–µ–∞–ª–∏–∑—É–µ—Ç–µ SASRec ‚Äî –æ–¥–Ω—É –∏–∑ —Å–∞–º—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
        "3) –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–µ—Ç–µ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –ø–æ—Ç–µ—Ä—å, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—è –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π\n",
        "4) –û—Ü–µ–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Å–¥–µ–ª–∞–µ—Ç–µ –≤—ã–≤–æ–¥—ã –æ –≤–ª–∏—è–Ω–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –Ω–∞ –∏—Ç–æ–≥–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olc1prCGfjjR"
      },
      "source": [
        "–í —ç—Ç–æ–º –¥–æ–º–∞—à–Ω–µ–º –∑–∞–¥–∞–Ω–∏–∏ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —ç—Ç–∞–ø—ã –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ‚Äî –æ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–µ.\n",
        "\n",
        "–í–æ –≤—Å–µ—Ö –∫–æ–¥–æ–≤—ã—Ö —è—á–µ–π–∫–∞—Ö, –æ—Ç–º–µ—á–µ–Ω–Ω—ã—Ö –∫–∞–∫ `# TODO: your code here`, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–ø–∏—Å–∞—Ç—å —Å–≤–æ–π –∫–æ–¥, —Ä–µ–∞–ª–∏–∑—É—é—â–∏–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —ç—Ç–∞–ø –æ–±—Ä–∞–±–æ—Ç–∫–∏, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –º–∞–ø–ø–∏–Ω–≥–∞, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞, –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏. –≠—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏, —Ñ–∏–ª—å—Ç—Ä—ã, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ –∏ –º–µ—Ç–æ–¥—ã.\n",
        "\n",
        "–í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ –ø–æ–¥–∑–∞–¥–∞–Ω–∏—è –≤–∞—Å –∂–¥—É—Ç –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã–µ —Ç–µ—Å—Ç—ã (sanity-checks) ‚Äî —ç—Ç–æ –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–ª—É–∂–∞—Ç –±–∞–∑–æ–≤–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –≤–∞—à–∏—Ö —Ä–µ—à–µ–Ω–∏–π, –Ω–æ –ù–ï —è–≤–ª—è—é—Ç—Å—è –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–º–∏. –ò—Ö –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏, –æ–¥–Ω–∞–∫–æ –ø–æ–º–æ–≥–∞–µ—Ç –±—ã—Å—Ç—Ä–æ –∑–∞–º–µ—Ç–∏—Ç—å —Ç–∏–ø–æ–≤—ã–µ –æ—à–∏–±–∫–∏ –∏ –æ–ø–µ—á–∞—Ç–∫–∏ –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —ç—Ç–∞–ø–∞—Ö.\n",
        "\n",
        "–°–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è:\n",
        "- –ó–∞ –∑–∞–¥–∞–Ω–∏—è 1 –∏ 2 (—Ä–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞, –æ–±—Ä–∞–±–æ—Ç–∫–∞) –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –±–∞–ª–ª—ã, –µ—Å–ª–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ ‚Äî —Ç–æ –µ—Å—Ç—å –≤–∞—à –∫–æ–¥ –ø—Ä–æ—Ö–æ–¥–∏—Ç –≤—Å–µ sanity-check —Ç–µ—Å—Ç—ã.\n",
        "\n",
        "- –ë–∞–ª–ª—ã –∑–∞ –∑–∞–¥–∞–Ω–∏—è 3‚Äì5 (—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π, —Ñ—É–Ω–∫—Ü–∏–π –æ–±—É—á–µ–Ω–∏—è –∏ –º–µ—Ç—Ä–∏–∫) –Ω–∞—á–∏—Å–ª—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ç–æ–º —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –≤ –∫–æ–Ω—Ü–µ –Ω–æ—É—Ç–±—É–∫–∞ –≤–∞—à–∞ –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—Ö–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ, –∞ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏/—Ç–µ—Å—Ç–µ –¥–æ—Å—Ç–∏–≥–∞—é—Ç –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π.\n",
        "\n",
        "–í–∞—à–∞ –∑–∞–¥–∞—á–∞: –ø—Ä–æ–π—Ç–∏ –≤–µ—Å—å –ø—É—Ç—å ‚Äî –æ—Ç —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1F06lkjfjjR"
      },
      "source": [
        "# üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–±–æ—á–µ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BHw4JjTfjjR"
      },
      "source": [
        "## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtyobnaKfjjR"
      },
      "outputs": [],
      "source": [
        "# –ù–∏–∂–µ –≤ —è—á–µ–π–∫–µ —Å—Ç–æ—è—Ç –∏–º–µ–Ω–Ω–æ —Ç–µ –≤–µ—Ä—Å–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —É –º–µ–Ω—è. –ú–æ–∂–µ—Ç–µ –º–µ–Ω—è—Ç—å –∏—Ö –Ω–∞ —Å–≤–æ–π —Å—Ç—Ä–∞—Ö –∏ —Ä–∏—Å–∫ :)\n",
        "!pip install datasets==4.4.1 -i https://pypi.org/simple\n",
        "!pip install polars==1.33.1 -i https://pypi.org/simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j0dQ5KafjjS"
      },
      "source": [
        "## üìö –ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbkKok0dfjjS"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import polars as pl\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAKFAslVfjjS"
      },
      "source": [
        "## ‚öôÔ∏è –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXXnSQUzfjjS"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "HOUR_SECONDS = 60 * 60\n",
        "DAY_SECONDS = 24 * HOUR_SECONDS\n",
        "\n",
        "VAL_SIZE = 1 * DAY_SECONDS\n",
        "TEST_SIZE = 1 * DAY_SECONDS\n",
        "\n",
        "LAST_TIMESTAMP = 26000000\n",
        "TEST_TIMESTAMP = LAST_TIMESTAMP - TEST_SIZE\n",
        "\n",
        "# Model\n",
        "HASH_DIM = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "VALID_BATCH_SIZE = 1024\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "EMBEDDING_DIM = 64\n",
        "NUM_HEADS = 2\n",
        "MAX_SEQ_LEN = 200\n",
        "MIN_SEQ_LEN = 2\n",
        "DROPOUT_RATE = 0.0\n",
        "NUM_TRANSFORMER_LAYERS = 2\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZlHMLqRfjjS"
      },
      "source": [
        "# üóÇÔ∏è –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik2EZ_EkfjjS"
      },
      "source": [
        "## üéµ –î–∞—Ç–∞—Å–µ—Ç: Yandex Music Behavior (Yambda)\n",
        "\n",
        "–î–∞—Ç–∞—Å–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞ –Ø–Ω–¥–µ–∫—Å–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ç—Ä–µ–∫–∞–º–∏. –ö–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –≤–∫–ª—é—á–∞—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–µ–∫–∞—Ö –∏ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏.\n",
        "\n",
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:\n",
        "- user_id: –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
        "- item_id: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Ç—Ä–µ–∫–æ–≤, —É—Å–ª—ã—à–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\n",
        "- timestamp: –≤—Ä–µ–º—è —Å–æ–±—ã—Ç–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö —Å —ç–ø–æ—Ö–∏\n",
        "- played_ratio_pct: –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ—Å–ª—É—à–∞–Ω–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ (0‚Äì100%)\n",
        "- is_organic: —Ñ–ª–∞–≥ –æ—Ä–≥–∞–Ω–∏—á–Ω–æ—Å—Ç–∏ (1 = –∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, 0 = —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è)\n",
        "- track_length_seconds: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö\n",
        "\n",
        "–î–∞—Ç–∞—Å–µ—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±–ª–∞–≥–æ–¥–∞—Ä—è –µ–≥–æ –º–∞—Å—à—Ç–∞–±—É, —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ–∞–ª—å–Ω–æ–º –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.\n",
        "\n",
        "\n",
        "Yambda –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö –∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è—Ö:\n",
        "\n",
        "–§–æ—Ä–º–∞—Ç—ã:\n",
        "\n",
        "- `flat`: —Å—ã—Ä—ã–µ –ª–æ–≥–∏ —Å–æ–±—ã—Ç–∏–π –±–µ–∑ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (–∫–∞–∂–¥–æ–µ —Å–æ–±—ã—Ç–∏–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞)\n",
        "- `sequence`: –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º (–≥–æ—Ç–æ–≤—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π)\n",
        "\n",
        "–†–∞–∑–º–µ—Ä—ã:\n",
        "- `50m`: 50 –º–ª–Ω —Å–æ–±—ã—Ç–∏–π (–∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)\n",
        "- `500m`: 500 –º–ª–Ω —Å–æ–±—ã—Ç–∏–π (—Å—Ä–µ–¥–Ω–µ–≥–æ –º–∞—Å—à—Ç–∞–±–∞)\n",
        "- `5b`: 5 –º–ª—Ä–¥ —Å–æ–±—ã—Ç–∏–π (–ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç)\n",
        "\n",
        "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º `sequence` —Ñ–æ—Ä–º–∞—Ç –≤ —Ä–∞–∑–º–µ—Ä–µ `50m` –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ø–æ —Ä–µ—Å—É—Ä—Å–∞–º. –û–¥–Ω–∞–∫–æ —Å—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ –Ω–∞ –±–æ–ª—å—à–∏—Ö –≤–∞—Ä–∏–∞—Ü–∏—è—Ö (`500m` –∏ `5b`) –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –Ω–∞–¥ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –≤—ã—Ä–∞–∂–µ–Ω—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —è—Ä—á–µ. –ñ–µ–ª–∞—é—â–∏–µ –º–æ–≥—É—Ç –∏–∑—É—á–∏—Ç—å —ç—Ç–æ –≤ [—Å—Ç–∞—Ç—å–µ –æ—Ç –Ø–Ω–¥–µ–∫—Å–∞](https://arxiv.org/abs/2505.22238).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TZN_kALfjjT"
      },
      "source": [
        "#### –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train/val/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n-mLfydfjjT"
      },
      "outputs": [],
      "source": [
        "# Source: https://huggingface.co/datasets/yandex/yambda\n",
        "\n",
        "def sequential_split_train_val_test(\n",
        "    df: pl.LazyFrame,\n",
        "    test_timestamp: int,\n",
        "    val_size: int = 0,\n",
        "    gap_size: int = 0,\n",
        "    drop_non_train_items: bool = False,\n",
        "    engine: str = 'streaming',\n",
        ") -> tuple[pl.LazyFrame, pl.LazyFrame | None, pl.LazyFrame]:\n",
        "    \"\"\"\n",
        "    Splits the dataset into training, validation, and test segments based on the provided timestamps.\n",
        "\n",
        "    The segments are defined as follows:\n",
        "    - Training set: [0, test_timestamp - gap_size - val_size - gap_size) if val_size != 0,\n",
        "                    otherwise [0, test_timestamp - gap_size)\n",
        "    - Validation set: [test_timestamp - val_size - gap_size, test_timestamp - gap_size), if val_size != 0\n",
        "    - Test set: [test_timestamp, +inf)\n",
        "\n",
        "    It retains only those users and items in the validation and test sets that exist in the training set.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    df : LazyFrame\n",
        "        The dataset in Polars' LazyFrame format.\n",
        "    test_timestamp : int | None\n",
        "        The timestamp marking the start of the test set;\n",
        "    val_size : int | None\n",
        "        The size of validation. If 0, no validation set is created.\n",
        "    gap_size : int\n",
        "        The duration of gap between training and validation/test sets.\n",
        "    drop_non_train_items : bool\n",
        "        Whether to drop items that are not in the training set.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    tuple[LazyFrame, LazyFrame | None, LazyFrame]\n",
        "        A tuple containing LazyFrames for the training, validation (if applicable), and test sets.\n",
        "    \"\"\"\n",
        "\n",
        "    def drop(df: pl.LazyFrame, unique_train_item_ids) -> pl.LazyFrame:\n",
        "        if not drop_non_train_items:\n",
        "            return df\n",
        "\n",
        "        return df.select(\n",
        "            'uid',\n",
        "            pl.all()\n",
        "            .exclude('uid')\n",
        "            .list.gather(\n",
        "                pl.col('item_id').list.eval(\n",
        "                    pl.arg_where(pl.element().is_in(unique_train_item_ids.get_column('item_id').implode()))\n",
        "                )\n",
        "            ),\n",
        "        ).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    train_timestamp = test_timestamp - gap_size - val_size - (gap_size if val_size != 0 else 0)\n",
        "\n",
        "    assert gap_size >= 0\n",
        "    assert val_size >= 0\n",
        "    assert train_timestamp > 0\n",
        "\n",
        "    df_lazy = df.lazy()\n",
        "\n",
        "    train = df_lazy.select(\n",
        "        'uid',\n",
        "        pl.all()\n",
        "        .exclude('uid')\n",
        "        .list.gather(pl.col('timestamp').list.eval(pl.arg_where(pl.element() < train_timestamp))),\n",
        "    ).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    unique_train_uids = train.select('uid').unique().collect(engine=engine)\n",
        "    unique_train_item_ids = train.explode('item_id').select('item_id').unique().collect(engine=engine)\n",
        "\n",
        "    validation = None\n",
        "    if val_size != 0:\n",
        "        validation = (\n",
        "            df_lazy.select(\n",
        "                'uid',\n",
        "                pl.all()\n",
        "                .exclude('uid')\n",
        "                .list.gather(\n",
        "                    pl.col('timestamp').list.eval(\n",
        "                        pl.arg_where(\n",
        "                            (pl.element() >= test_timestamp - val_size - gap_size)\n",
        "                            & (pl.element() < test_timestamp - gap_size)\n",
        "                        )\n",
        "                    )\n",
        "                ),\n",
        "            )\n",
        "            .with_columns(\n",
        "                pl.col('uid').is_in(unique_train_uids.get_column('uid').implode()).alias('uid_in_train')\n",
        "            )  # to prevent filter reordering\n",
        "            .filter('uid_in_train')\n",
        "            .drop('uid_in_train')\n",
        "        )\n",
        "\n",
        "        validation = drop(validation, unique_train_item_ids).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    test = (\n",
        "        df_lazy.select(\n",
        "            'uid',\n",
        "            pl.all()\n",
        "            .exclude('uid')\n",
        "            .list.gather(pl.col('timestamp').list.eval(pl.arg_where(pl.element() >= test_timestamp))),\n",
        "        )\n",
        "        #\n",
        "        .with_columns(\n",
        "            pl.col('uid').is_in(unique_train_uids.get_column('uid').implode()).alias('uid_in_train')\n",
        "        )  # to prevent filter reordering\n",
        "        .filter('uid_in_train')\n",
        "        .drop('uid_in_train')\n",
        "    )\n",
        "\n",
        "    test = drop(test, unique_train_item_ids).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    return train, validation, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2osV0__OfjjT"
      },
      "source": [
        "## üîç –ü—Ä–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
        "\n",
        "–í —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –í–æ –º–Ω–æ–≥–∏—Ö —Å—Ç–∞—Ç—å—è—Ö –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç–æ—è–≤—à–∞—è—Å—è —Å—Ö–µ–º–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:\n",
        "\n",
        "1. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–¥–∫–∏—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π**: –£–¥–∞–ª—è—é—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∏ –∞–π—Ç–µ–º—ã (—Ç–æ–≤–∞—Ä—ã/—Ñ–∏–ª—å–º—ã/etc), —É –∫–æ—Ç–æ—Ä—ã—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –º–µ–Ω—å—à–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞. –≠—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å –º–∞—Ç—Ä–∏—Ü—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç —à—É–º. –î–ª—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ Amazon, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–≤–æ–ª—å–Ω–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã –≤ –∞–∫–∞–¥–µ–º–∏–∏, –µ—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –Ω–æ—Ç–∞—Ü–∏—è '5-core'. –û–¥–Ω–∞–∫–æ, –¥–ª—è Yambda –º—ã –ø—Ä–æ–ø—É—Å—Ç–∏–º —ç—Ç–æ—Ç —à–∞–≥, –∞–∫ –∫–∞–∫ –ø–æ—Ö–æ–∂–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±—ã–ª–∞ —Å–¥–µ–ª–∞–Ω–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞.\n",
        "\n",
        "2. **–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö**: –î–æ–≤–æ–ª—å–Ω–æ —á–∞—Å—Ç–æ –≤ —Ä–∞–±–æ—Ç–∞—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è leave-one-out (LOO) –ø–æ–¥—Ö–æ–¥ (–æ—Å—Ç–∞–≤–ª–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–π—Ç–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞, –ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –æ—Å—Ç–∞–ª—å–Ω–æ–µ train), –Ω–æ –º—ã —Å–¥–µ–ª–∞–µ–º time-split, —Ç–∞–∫ –∫–∞–∫ LOO –ø–æ—Ä–∞–∂–¥–∞–µ—Ç —É—Ç–µ—á–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (`data leakage`) ‚Äî –º–æ–¥–µ–ª—å –Ω–µ –¥–æ–ª–∂–Ω–∞ –≤–∏–¥–µ—Ç—å –±—É–¥—É—â–∏–µ —Å–æ–±—ã—Ç–∏—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏, –∏ –ø–ª–æ—Ö–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å production —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏.\n",
        "\n",
        "3. **–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏**: –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é -- –¥–ª—è –ø–æ–¥–±—Ä–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ early-stopping'–∞, –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –±—É–¥–µ–º –ø–æ–ª—É—á–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwwdsnwBfjjT"
      },
      "source": [
        "## üõ†Ô∏è Task 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (2 –±–∞–ª–ª–∞)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQtfWFWIfjjT"
      },
      "source": [
        "1Ô∏è‚É£ –°–∫–∞—á–∞–π—Ç–µ –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ä–µ–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π —Å —Ç—Ä–µ–∫–∞–º–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viKiSaEKfjjT"
      },
      "outputs": [],
      "source": [
        "format = 'sequential'\n",
        "size = '50m'\n",
        "events = 'listens'\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç —Å Hugging Face Hub\n",
        "listens_data = load_dataset('yandex/yambda', data_dir=f'{format}/{size}', data_files=f'{events}.parquet')\n",
        "\n",
        "# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Polars DataFrame –¥–ª—è –¥–∞–ª—å–Ω–µ–π–Ω–µ–π —Ä–∞–±–æ—Ç—ã\n",
        "yambda_df = pl.from_arrow(listens_data['train'].data.table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNanksDRfjjT"
      },
      "outputs": [],
      "source": [
        "def test_yambda_data_loading():\n",
        "    assert isinstance(yambda_df, pl.DataFrame), 'yambda_df –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å Polars DataFrame'\n",
        "    assert yambda_df.shape == (9238, 6), f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {yambda_df.shape}'\n",
        "\n",
        "    expected_cols = {'uid', 'timestamp', 'item_id', 'is_organic', 'played_ratio_pct', 'track_length_seconds'}\n",
        "    assert set(yambda_df.columns) == expected_cols, f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {yambda_df.columns}'\n",
        "\n",
        "    assert yambda_df['item_id'].dtype == pl.List(pl.UInt32), 'item_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å List[UInt32]'\n",
        "    assert yambda_df['timestamp'].dtype == pl.List(pl.UInt32), 'timestamp –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å List[UInt32]'\n",
        "\n",
        "    assert yambda_df['item_id'].list.len().min() > 0, '–ï—Å—Ç—å –ø—É—Å—Ç—ã–µ –∏—Å—Ç–æ—Ä–∏–∏'\n",
        "\n",
        "    print('‚úÖ test_yambda_data_loading: OK')\n",
        "\n",
        "test_yambda_data_loading()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMbeUvWHfjjT"
      },
      "source": [
        "2Ô∏è‚É£ –û—Ç—Ñ–∏–ª—å—Ç—Ä—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ, –æ—Å—Ç–∞–≤–∏–≤ —Ç–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, uid –∫–æ—Ç–æ—Ä—ã—Ö –∫—Ä–∞—Ç–µ–Ω 200, –∏ —Å–æ–±—ã—Ç–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (–æ—Ä–≥–∞–Ω–∏—á–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è) –∏ –±—ã–ª–∏ –ø—Ä–æ—Å–ª—É—à–∞–Ω—ã –±–æ–ª–µ–µ —á–µ–º –Ω–∞–ø–æ–ª–æ–≤–∏–Ω—É. –£–¥–∞–ª–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏–∏,–≥–¥–µ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å–æ–±—ã—Ç–∏–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏. –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –º–æ–¥–µ–ª–∏ —É—á–∏—Ç—å—Å—è –Ω–∞ –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9ou8IARfjjT"
      },
      "outputs": [],
      "source": [
        "yambda_df = ...  # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HTturbHfjjU"
      },
      "outputs": [],
      "source": [
        "def test_yambda_filtering():\n",
        "    assert yambda_df.shape[0] == 4289, \\\n",
        "        f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {yambda_df.shape[0]}'\n",
        "\n",
        "    expected_columns = {'uid', 'timestamp', 'item_id'}\n",
        "    actual_columns = set(yambda_df.columns)\n",
        "    assert actual_columns == expected_columns, \\\n",
        "        f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏. –û–∂–∏–¥–∞–ª–æ—Å—å: {expected_columns}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_columns}'\n",
        "\n",
        "    assert yambda_df['timestamp'].dtype == pl.List(pl.UInt32), \\\n",
        "        f\"timestamp –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å List[UInt32], –ø–æ–ª—É—á–µ–Ω–æ: {yambda_df['timestamp'].dtype}\"\n",
        "    assert yambda_df['item_id'].dtype == pl.List(pl.UInt32), \\\n",
        "        f\"item_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å List[UInt32], –ø–æ–ª—É—á–µ–Ω–æ: {yambda_df['item_id'].dtype}\"\n",
        "\n",
        "    seq_lengths = yambda_df['item_id'].list.len()\n",
        "    assert seq_lengths.min() >= 1, \\\n",
        "        f'–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å >= 1, –ø–æ–ª—É—á–µ–Ω–æ: {seq_lengths.min()}'\n",
        "    assert seq_lengths.sum() == 7587469, \\\n",
        "        f'–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π –Ω–µ–≤–µ—Ä–Ω–æ. –û–∂–∏–¥–∞–ª–æ—Å—å: 7587469, –ø–æ–ª—É—á–µ–Ω–æ: {seq_lengths.sum()}'\n",
        "\n",
        "    unique_items = yambda_df.select('item_id').explode('item_id').unique().shape[0]\n",
        "    assert unique_items == 304787, \\\n",
        "        f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–π—Ç–µ–º–æ–≤ –Ω–µ–≤–µ—Ä–Ω–æ. –û–∂–∏–¥–∞–ª–æ—Å—å: 304787, –ø–æ–ª—É—á–µ–Ω–æ: {unique_items}'\n",
        "\n",
        "    print('‚úÖ test_yambda_filtering: OK')\n",
        "\n",
        "test_yambda_filtering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKFs6KQRfjjU"
      },
      "source": [
        "3Ô∏è‚É£ –ü–æ–ª—É—á–∏—Ç–µ –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID —Ç—Ä–µ–∫–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —Å–æ–∑–¥–∞–π—Ç–µ –º–∞–ø–ø–∏–Ω–≥: —Å—Ç–∞—Ä—ã–π_id - –Ω–æ–≤—ã–π_id, –≥–¥–µ –Ω–æ–≤—ã–π_id –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ N - 1.\n",
        "\n",
        "–ú–æ–¥–µ–ª–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Ç—Ä–µ–±—É—é—Ç, —á—Ç–æ–±—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ ID —Ç—Ä–µ–∫–æ–≤) –±—ã–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Ü–µ–ª—ã–º–∏ —á–∏—Å–ª–∞–º–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ N-1, –≥–¥–µ N ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤. –î–∞—Ç–∞—Å–µ—Ç Yambda —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ ID —Ç—Ä–µ–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [100, 5000, 7, 12000, ...]) ‚Äî —ç—Ç–æ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –¥–ª—è embedding-—Ç–∞–±–ª–∏—Ü."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ4VliVEfjjU"
      },
      "outputs": [],
      "source": [
        "unique_items = ... # TODO: your code here\n",
        "\n",
        "item_mapping = ...  # TODO: your code here\n",
        "\n",
        "yambda_df = yambda_df.with_columns([\n",
        "    pl.col('item_id')\n",
        "        .map_elements(\n",
        "            lambda items: [item_mapping[item] for item in items],\n",
        "            return_dtype=pl.List(pl.UInt32)\n",
        "        )\n",
        "        .alias('item_id')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MltQKQ8cfjjU"
      },
      "outputs": [],
      "source": [
        "def test_item_mapping():\n",
        "    assert unique_items.shape == (304787, 2), f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä unique_items: {unique_items.shape}'\n",
        "    assert set(unique_items.columns) == {'new_item_id', 'item_id'}, '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ unique_items'\n",
        "\n",
        "    assert len(item_mapping) == 304787, f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä item_mapping: {len(item_mapping)}'\n",
        "    assert item_mapping[50] == 0 and item_mapping[175] == 1 and item_mapping[195] == 2, \\\n",
        "        '–ù–µ–≤–µ—Ä–Ω—ã–µ –ø–µ—Ä–≤—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏'\n",
        "\n",
        "    new_ids = unique_items['new_item_id']\n",
        "    assert new_ids.min() == 0 and new_ids.max() == 304786, 'new_item_id –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ [0, 304786]'\n",
        "\n",
        "    all_ids = yambda_df.select('item_id').explode('item_id')['item_id']\n",
        "    assert all_ids.min() == 0 and all_ids.max() == 304786, 'item_id –≤ yambda_df –Ω–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã'\n",
        "    assert all_ids.n_unique() == 304787, '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö item_id –∏–∑–º–µ–Ω–∏–ª–æ—Å—å'\n",
        "\n",
        "    print('‚úÖ test_item_mapping: OK')\n",
        "\n",
        "test_item_mapping()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHnmCq7XfjjU"
      },
      "source": [
        "4Ô∏è‚É£ –†–∞–∑–¥–µ–ª–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–∞ —Ç—Ä–∏ –Ω–µ–ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏—Ö—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–∞.\n",
        "\n",
        "- –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –∏ —Ç–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∏ –¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ –æ–¥–Ω–æ–º—É –¥–Ω—é —Å–æ–±—ã—Ç–∏–π –∫–∞–∂–¥–∞—è, –∞ –æ–±—É—á–∞—é—â–∞—è ‚Äî –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ –Ω–∏—Ö.\n",
        "- –ó–∞–∑–æ—Ä—ã –º–µ–∂–¥—É –ø–µ—Ä–∏–æ–¥–∞–º–∏ –¥–æ–ª–∂–Ω—ã –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å (–¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –∏–¥—Ç–∏ \"–≤–ø–ª–æ—Ç–Ω—É—é\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDS06D6vfjjU"
      },
      "outputs": [],
      "source": [
        "train_events_df, valid_events_df, eval_events_df = ...  # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13X5uop0fjjU"
      },
      "outputs": [],
      "source": [
        "def test_yambda_train_val_test_split():\n",
        "    assert train_events_df.shape[0] == (4284), \\\n",
        "        f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {train_events_df.shape[0]}'\n",
        "    assert valid_events_df.shape[0] == (1356), \\\n",
        "        f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {valid_events_df.shape[0]}'\n",
        "    assert eval_events_df.shape[0] == (1407), \\\n",
        "        f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {eval_events_df.shape[0]}'\n",
        "\n",
        "    assert isinstance(train_events_df, pl.DataFrame), '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø'\n",
        "    assert isinstance(valid_events_df, pl.DataFrame), '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø'\n",
        "    assert isinstance(eval_events_df, pl.DataFrame), '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø'\n",
        "\n",
        "    assert train_events_df.select(pl.col('item_id').list.len()).sum().item() == 7510554, \\\n",
        "        '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π –≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ'\n",
        "    assert valid_events_df.select(pl.col('item_id').list.len()).sum().item() == 35933, \\\n",
        "        '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ'\n",
        "    assert eval_events_df.select(pl.col('item_id').list.len()).sum().item() == 40961, \\\n",
        "        '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ'\n",
        "\n",
        "    print('‚úÖ test_yambda_train_val_test_split: OK')\n",
        "\n",
        "test_yambda_train_val_test_split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGwbwJmvfjjU"
      },
      "source": [
        "5Ô∏è‚É£ –°–æ–µ–¥–∏–Ω–∏—Ç–µ —Ç—Ä–∏ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö –≤—ã–±–æ—Ä–∫–∏ (`train`/`val`/`test`) –≤ –æ–¥–Ω—É —Ç–∞–±–ª–∏—Ü—É –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º (`uid`). –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ–≥–æ –∏—Å—Ç–æ—Ä–∏—é –Ω–∞ –≤—Å–µ—Ö —Ç—Ä—ë—Ö —ç—Ç–∞–ø–∞—Ö: –æ–±—É—á–µ–Ω–∏–µ, –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ —Ç–µ—Å—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zgsnunofjjU"
      },
      "outputs": [],
      "source": [
        "joined_events_df = ...  # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaQgBvssfjjU"
      },
      "outputs": [],
      "source": [
        "def test_yambda_all_join():\n",
        "    assert joined_events_df.shape[0] == 4284, \\\n",
        "        f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {joined_events_df.shape[0]}'\n",
        "\n",
        "    assert min(list(map(len, joined_events_df['item_id'].to_list()))) == 1\n",
        "    assert max(list(map(len, joined_events_df['item_id'].to_list()))) == 25643\n",
        "\n",
        "    print('‚úÖ test_yambda_all_join: OK')\n",
        "\n",
        "test_yambda_all_join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHBKhHb6fjjU"
      },
      "source": [
        "6Ô∏è‚É£ –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –æ–±—É—á–∞—é—â—É—é, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏.\n",
        "\n",
        "–î–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –æ—Å—Ç–∞–≤—å—Ç–µ —Ç–æ–ª—å–∫–æ —Ç–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, —á—å–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–±—ã—Ç–∏–π (–Ω–µ –º–µ–Ω–µ–µ MIN_SEQ_LEN —Ç—Ä–µ–∫–æ–≤).\n",
        "\n",
        "–î–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ —Å–æ–∑–¥–∞–π—Ç–µ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ —Å–æ–∑–¥–∞–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–º–ø–ª–æ–≤, –≥–¥–µ –∏—Å—Ç–æ—Ä–∏—è —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –≤—Å–µ—Ö train —Å–æ–±—ã—Ç–∏–π –ø–ª—é—Å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º—ã–µ valid —Å–æ–±—ã—Ç–∏—è (1-–µ, 1-2-–µ, 1-2-3-–µ –∏ —Ç.–¥.). –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ü–µ–Ω–∏—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç—Ä–µ–∫ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏.\n",
        "\n",
        "–î–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –ø—Ä–æ–¥–µ–ª–∞–π—Ç–µ —Ç–æ –∂–µ —Å–∞–º–æ–µ —á—Ç–æ –∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –Ω–æ –Ω–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø–æ–ª–Ω–æ–π train –∏—Å—Ç–æ—Ä–∏–∏ + –≤—Å–µ valid —Å–æ–±—ã—Ç–∏—è, –∑–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–π—Ç–µ test —Å–æ–±—ã—Ç–∏—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkiHBdKdfjjU"
      },
      "outputs": [],
      "source": [
        "train_data = ... # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSppjCNkfjjU"
      },
      "outputs": [],
      "source": [
        "def test_train_data():\n",
        "    assert train_data.shape == (4228, 3), f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {train_data.shape}'\n",
        "    assert train_data.columns == ['uid', 'timestamp', 'item_id'], '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏'\n",
        "\n",
        "    assert train_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        '–ï—Å—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ—Ä–æ—á–µ MIN_SEQ_LEN'\n",
        "\n",
        "    assert train_data['item_id'].list.len().sum() == 7510498, '–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π'\n",
        "\n",
        "    assert train_data['uid'].head(5).to_list() == [600, 800, 1000, 1400, 1600], '–ù–µ–≤–µ—Ä–Ω—ã–µ –ø–µ—Ä–≤—ã–µ uid'\n",
        "\n",
        "    print('‚úÖ test_train_data: OK')\n",
        "\n",
        "test_train_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1pZSBDofjjU"
      },
      "outputs": [],
      "source": [
        "valid_data = ...  # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_ujdnNGfjjV"
      },
      "outputs": [],
      "source": [
        "def test_valid_data():\n",
        "    assert valid_data.shape == (35933, 3), f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {valid_data.shape}'\n",
        "    assert valid_data.columns == ['uid', 'timestamp', 'item_id'], '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏'\n",
        "\n",
        "    assert valid_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        '–ï—Å—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ—Ä–æ—á–µ MIN_SEQ_LEN'\n",
        "\n",
        "    assert valid_data['item_id'].list.len().sum() == 195225055, '–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π'\n",
        "    assert valid_data['uid'].head(5).to_list() == [600, 600, 600, 600, 600], '–ù–µ–≤–µ—Ä–Ω—ã–µ –ø–µ—Ä–≤—ã–µ uid'\n",
        "\n",
        "    first_user_lens = valid_data.filter(pl.col('uid') == 100)['item_id'].list.len().to_list()[:5]\n",
        "    assert first_user_lens == sorted(first_user_lens), '–î–ª–∏–Ω—ã –¥–æ–ª–∂–Ω—ã —Ä–∞—Å—Ç–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ'\n",
        "\n",
        "    print('‚úÖ test_valid_data: OK')\n",
        "\n",
        "test_valid_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZtGyiqcfjjV"
      },
      "outputs": [],
      "source": [
        "eval_data = ...  # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eCGOhRBfjjV"
      },
      "outputs": [],
      "source": [
        "def test_eval_data():\n",
        "    assert eval_data.shape == (40961, 3), f'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {eval_data.shape}'\n",
        "    assert eval_data.columns == ['uid', 'timestamp', 'item_id'], '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        '–ï—Å—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ—Ä–æ—á–µ MIN_SEQ_LEN'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().sum() == 212124968, '–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π'\n",
        "    assert eval_data['uid'].head(5).to_list() == [600, 600, 600, 600, 600], '–ù–µ–≤–µ—Ä–Ω—ã–µ –ø–µ—Ä–≤—ã–µ uid'\n",
        "\n",
        "    first_user_lens = eval_data.filter(pl.col('uid') == 100)['item_id'].list.len().head(5).to_list()\n",
        "    assert first_user_lens == sorted(first_user_lens), '–î–ª–∏–Ω—ã –¥–æ–ª–∂–Ω—ã —Ä–∞—Å—Ç–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().sum() > valid_data['item_id'].list.len().sum(), \\\n",
        "        'eval_data –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ valid_data'\n",
        "\n",
        "    print('‚úÖ test_eval_data: OK')\n",
        "\n",
        "test_eval_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8oyiPe0fjjV"
      },
      "source": [
        "–°–µ–º–ø–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –±—É–¥–µ–º –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –±—É–¥—É—Ç –∏–º–µ—Ç—å —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É:\n",
        "\n",
        "- `history`\n",
        "    - `item_id` (–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)\n",
        "    - `lengths` (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)\n",
        "    - `positions` (–Ω–æ–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–π –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ)\n",
        "- `labels`\n",
        "    - `item_id` (–ø–æ–∑–∏—Ç–∏–≤—ã, –∫–æ—Ç–æ—Ä–æ—ã–π –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å, a.k.a —Å–ª–µ–¥—É—é—â–µ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kfhnDEDfjjV"
      },
      "source": [
        "7Ô∏è‚É£ –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–ª–∞—Å—Å `YambdaDataset`, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç, —É–¥–æ–±–Ω—ã–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.\n",
        "\n",
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n",
        "\n",
        "- –í –º–µ—Ç–æ–¥–µ `__len__`: –≤–µ—Ä–Ω–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
        "\n",
        "- –í –º–µ—Ç–æ–¥–µ `__getitem__`: –ø–æ –∏–Ω–¥–µ–∫—Å—É –ø–æ–ª—É—á–∏—Ç–µ —Å–µ–º–ø–ª –∏ –≤–µ—Ä–Ω–∏—Ç–µ —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –∫–ª—é—á–∞–º–∏:\n",
        "\n",
        "    - `history` -- —Å–ª–æ–≤–∞—Ä—å, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Ç–æ, —á—Ç–æ –≤–∏–¥–∏—Ç –º–æ–¥–µ–ª—å):\n",
        "        - `item_id` -- –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–∫–æ–≤ (–±–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–±—ã—Ç–∏—è –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏)\n",
        "        - `lengths` -- –¥–ª–∏–Ω–∞ —ç—Ç–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "        - `positions` -- –ø–æ—Ä—è–¥–∫–æ–≤—ã–µ –Ω–æ–º–µ—Ä–∞ —Å–æ–±—ã—Ç–∏–π (–æ—Ç 0 –¥–æ –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)\n",
        "\n",
        "    - `labels` -- —Å–ª–æ–≤–∞—Ä—å, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∏–π —Ç–∞—Ä–≥–µ—Ç—ã (—Ç–æ, —á—Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å):\n",
        "        - `item_id` -- –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ü–µ–ª–µ–≤—ã—Ö —Ç—Ä–µ–∫–æ–≤ (–±–µ–∑ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–±—ã—Ç–∏—è –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏)\n",
        "\n",
        "    - –û–≥—Ä–∞–Ω–∏—á—å—Ç–µ –æ–±–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ `item_id` –¥–æ `max_seq_len`, –æ—Å—Ç–∞–≤–ª—è—è –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è ‚Äî –æ–Ω–∏ –æ—Ç—Ä–∞–∂–∞—é—Ç —Å–≤–µ–∂–∏–π –∏–Ω—Ç–µ—Ä–µ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
        "\n",
        "–°–¥–≤–∏–≥ –º–µ–∂–¥—É `history/item_id` –∏ `labels/item_id` —Å–æ–∑–¥–∞—ë—Ç –ø–∞—Ä—ã \"–∫–æ–Ω—Ç–µ–∫—Å—Ç-—Ç–∞—Ä–≥–µ—Ç\", –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ö–∞–∂–¥–æ–µ —Å–æ–±—ã—Ç–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—É—á–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–∞—Ä–≥–µ—Ç (—Å–ª–µ–¥—É—é—â–∏–π –∞–π—Ç–µ–º), —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —É—á–∏—Ç—å—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç—Ä–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0wQcZmkfjjV"
      },
      "outputs": [],
      "source": [
        "class YambdaDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for sequential user interaction histories.\n",
        "\n",
        "    Transforms user listening sequences into format suitable for training autoregressive\n",
        "    recommendation models. Creates (history, target) pairs where the target is shifted\n",
        "    by one event forward relative to the history.\n",
        "\n",
        "    For each user:\n",
        "    - history: events [0:-1] (all except last)\n",
        "    - labels: events [1:] (all except first)\n",
        "\n",
        "    This enables the model to learn predicting the next track based on previous events\n",
        "    in the user's history.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe : pl.DataFrame\n",
        "        DataFrame with columns 'uid', 'timestamp', 'item_id', where item_id\n",
        "        contains sequences (lists) of user interaction events.\n",
        "    max_seq_len : int\n",
        "        Maximum sequence length. Histories are truncated keeping the last\n",
        "        (most recent) events.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Dict[str, Any]]\n",
        "        Dictionary with keys 'history' and 'labels':\n",
        "        - history['item_id']: list of track IDs\n",
        "        - history['lengths']: sequence length\n",
        "        - history['positions']: ordinal numbers [0, 1, ..., len-1]\n",
        "        - labels['item_id']: list of target IDs (targets)\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> dataset = YambdaDataset(train_data, max_seq_len=200)\n",
        "    >>> sample = dataset[0]\n",
        "    >>> sample['history']['item_id']  # [track_id_1, track_id_2, track_id_3, ...]\n",
        "    >>> sample['labels']['item_id']   # [track_id_2, track_id_3, track_id_4, ...]\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            dataframe: pl.DataFrame,\n",
        "            max_seq_len: int,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the number of samples in the dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        int\n",
        "            Number of rows in the DataFrame.\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, List[int]]:\n",
        "        \"\"\"\n",
        "        Retrieves a sample by index and transforms it into format for training.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        index : int\n",
        "            Index of the sample in the dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, Dict[str, Any]]\n",
        "            Dictionary with 'history' (context) and 'labels' (targets).\n",
        "            History is truncated to max_seq_len, keeping last events.\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZWn6SDFfjjV"
      },
      "outputs": [],
      "source": [
        "def test_yambda_dataset():\n",
        "    max_seq_len = 20\n",
        "    dataset = YambdaDataset(train_data, max_seq_len=max_seq_len)\n",
        "\n",
        "    assert len(dataset) == train_data.shape[0], \\\n",
        "        f'–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞. –û–∂–∏–¥–∞–ª–æ—Å—å: {train_data.shape[0]}, –ø–æ–ª—É—á–µ–Ω–æ: {len(dataset)}'\n",
        "\n",
        "    sample = dataset[0]\n",
        "    assert isinstance(sample, dict), '–°–µ–º–ø–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—ë–º'\n",
        "    assert 'history' in sample and 'labels' in sample, \"–ö–ª—é—á–∏ 'history' –∏ 'labels' –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã\"\n",
        "\n",
        "    hist = sample['history']\n",
        "    assert 'item_id' in hist and 'lengths' in hist and 'positions' in hist, \"–ù–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–ª—é—á–∏ –≤ 'history'\"\n",
        "    assert isinstance(hist['item_id'], list), \"'history/item_id' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º\"\n",
        "    assert isinstance(hist['positions'], list), \"'history/positions' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º\"\n",
        "    assert isinstance(hist['lengths'], int), \"'history/lengths' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å int\"\n",
        "    assert len(hist['positions']) == hist['lengths'] == len(hist['item_id']), '–î–ª–∏–Ω—ã –ø–æ–∑–∏—Ü–∏–π –∏ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç'\n",
        "    assert hist['lengths'] <= max_seq_len, '–î–ª–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–µ–≤—ã—à–∞–µ—Ç max_seq_len'\n",
        "\n",
        "    labels = sample['labels']\n",
        "    assert 'item_id' in labels, \"'labels' –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'item_id'\"\n",
        "    assert isinstance(labels['item_id'], list), \"'labels/item_id' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º\"\n",
        "    assert len(labels['item_id']) == hist['lengths'], '–†–∞–∑–º–µ—Ä—ã history –∏ labels –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç'\n",
        "\n",
        "    row_item_id = train_data['item_id'][0]\n",
        "    if len(row_item_id) > max_seq_len:\n",
        "        row_item_id = row_item_id[-(max_seq_len+1):]\n",
        "    expected_history = row_item_id[:-1]\n",
        "    expected_labels = row_item_id[1:]\n",
        "    assert tuple(hist['item_id']) == tuple(expected_history), f\"–ù–µ–≤–µ—Ä–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è! {hist['item_id']} vs {expected_history}\"\n",
        "    assert tuple(labels['item_id']) == tuple(expected_labels), f\"–ù–µ–≤–µ—Ä–Ω—ã–µ —Ç–∞—Ä–≥–µ—Ç—ã! {labels['item_id']} vs {expected_labels}\"\n",
        "\n",
        "    print('‚úÖ test_yambda_dataset: OK')\n",
        "\n",
        "test_yambda_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8mF58JTfjjV"
      },
      "source": [
        "8Ô∏è‚É£ –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `collate_fn`, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –±–∞—Ç—á–∞ —Å–µ–º–ø–ª–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç, —É–¥–æ–±–Ω—ã–π –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –º–æ–¥–µ–ª—å.\n",
        "\n",
        "–§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞:\n",
        "- –ü—Ä–∏–Ω–∏–º–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π (–±–∞—Ç—á —Å–µ–º–ø–ª–æ–≤ –∏–∑ `YambdaDataset`)\n",
        "- –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å –≤—Å–µ —Å–ø–∏—Å–∫–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –µ–¥–∏–Ω—ã–π PyTorch —Ç–µ–Ω–∑–æ—Ä\n",
        "- –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å –≤—Å–µ —Å–∫–∞–ª—è—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n",
        "- –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –µ–¥–∏–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–º–µ—é—Ç —Ç–∏–ø `torch.Tensor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dgA4KZlfjjV"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Collates a batch of samples into a single batched tensor representation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch : List[Dict[str, Any]]\n",
        "        A list of samples returned by __getitem__, where each sample is a dictionary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Any]\n",
        "        A dictionary with the same structure as input samples, but where all leaf values\n",
        "        are PyTorch tensors of dtype torch.long. Nested dictionaries are preserved,\n",
        "        with tensors at the leaf level.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> batch = [\n",
        "    ...     {\n",
        "    ...         'history': {'item_id': [1, 2, 3], 'lengths': 3, 'positions': [0, 1, 2]},\n",
        "    ...         'labels': {'item_id': [2, 3, 4]}\n",
        "    ...     },\n",
        "    ...     {\n",
        "    ...         'history': {'item_id': [5, 6], 'lengths': 2, 'positions': [0, 1]},\n",
        "    ...         'labels': {'item_id': [6, 7]}\n",
        "    ...     }\n",
        "    ... ]\n",
        "    >>> result = collate_fn(batch)\n",
        "    >>> result['history']['item_id']\n",
        "    tensor([[1, 2, 3, 5, 6]], dtype=torch.long)\n",
        "    >>> result['history']['lengths']\n",
        "    tensor([3, 2], dtype=torch.long)\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy24_uSOfjjV"
      },
      "outputs": [],
      "source": [
        "def test_collate_fn():\n",
        "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –±–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–µ–π collate_fn.\"\"\"\n",
        "\n",
        "    batch = [\n",
        "        {'history': {'item_id': [1, 2, 3], 'lengths': 3, 'positions': [0, 1, 2]}, 'labels': {'item_id': [2, 3, 4]}},\n",
        "        {'history': {'item_id': [5, 6], 'lengths': 2, 'positions': [0, 1]}, 'labels': {'item_id': [6, 7]}},\n",
        "    ]\n",
        "\n",
        "    result = collate_fn(batch)\n",
        "\n",
        "    assert isinstance(result['history']['item_id'], torch.Tensor), 'item_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–µ–Ω–∑–æ—Ä–æ–º'\n",
        "    assert result['history']['item_id'].dtype == torch.long, 'dtype –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å long'\n",
        "\n",
        "    assert result['history']['item_id'].tolist() == [1, 2, 3, 5, 6], '–ù–µ–≤–µ—Ä–Ω–∞—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è item_id'\n",
        "    assert result['history']['positions'].tolist() == [0, 1, 2, 0, 1], '–ù–µ–≤–µ—Ä–Ω–∞—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è positions'\n",
        "\n",
        "    assert result['history']['lengths'].tolist() == [3, 2], '–ù–µ–≤–µ—Ä–Ω—ã–µ lengths'\n",
        "\n",
        "    assert result['labels']['item_id'].tolist() == [2, 3, 4, 6, 7], '–ù–µ–≤–µ—Ä–Ω—ã–µ labels'\n",
        "\n",
        "    assert result['history']['lengths'].sum().item() == len(result['history']['item_id']), \\\n",
        "        '–°—É–º–º–∞ lengths != –¥–ª–∏–Ω–∞ item_id'\n",
        "\n",
        "    print('‚úÖ test_collate_fn: OK')\n",
        "\n",
        "test_collate_fn()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_gC5wKZfjjW"
      },
      "source": [
        "# –ü—Ä–æ SASRec –º–æ–¥–µ–ª—å"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KxkgUKXfjjW"
      },
      "source": [
        "## üìñ –ù–µ–º–Ω–æ–≥–æ —Ç–µ–æ—Ä–∏–∏ –ø—Ä–æ SASRec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi01CWt3fjjW"
      },
      "source": [
        "<img src=\"sasrec.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd7Hnmo_fjjW"
      },
      "source": [
        "### üßê **–ß—Ç–æ —Ç–∞–∫–æ–µ SASRec?**\n",
        "SASRec (Self-Attentive Sequential Recommendation) - —ç—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –∏ –º–µ—Ö–∞–Ω–∏–∑–º–µ —Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏—è (self-attention). –ú–æ–¥–µ–ª—å –±—ã–ª–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –≤ 2018 –≥–æ–¥—É (Wang-Cheng Kang, Julian McAuley). –ï—ë —Ü–µ–ª—å - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –∫–∞–∫ –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ, —Ç–∞–∫ –∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –µ–≥–æ –±—É–¥—É—â–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã. SASRec –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –∏–¥–µ–∏ self-attention –∏–∑ NLP –¥–ª—è –∑–∞–¥–∞—á–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –µ–π –±—ã—Ç—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ–π, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–π –∏ –±—ã—Å—Ç—Ä–æ–π –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å RNN –∏ CNN. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç—å—è, –∫–æ—Ç–æ—Ä–∞—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ–¥—Ö–æ–¥ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–æ—Ç [—Ç—É—Ç](http://arxiv.org/abs/1808.09781).\n",
        "\n",
        "\n",
        "### üëÄ **–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏:**\n",
        "\n",
        "- Embedding Layer: –∫–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –æ–±—É—á–∞–µ–º—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ $d$. –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—á—ë—Ç–∞ –ø–æ—Ä—è–¥–∫–∞ —Å–æ–±—ã—Ç–∏–π.\n",
        "- Transformer Encoder: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ $l$ –±–ª–æ–∫–æ–≤ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–µ—Ä–∞ —Å –∫–∞—É–∑–∞–ª—å–Ω–æ–π –º–∞—Å–∫–æ–π. –ö–∞–∂–¥—ã–π –±–ª–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç self-attention —Å–ª–æ–π –∏ position-wise feed-forward —Å–ª–æ–π, –∞ —Ç–∞–∫–∂–µ residual connection –∏ layernorm.\n",
        "- Prediction Layer: –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ $t$ –≤—ã—Ö–æ–¥ —ç–Ω–∫–æ–¥–µ—Ä–∞ $\\mathbf{F}^{(b)}_t$ —Å–∫–∞–ª—è—Ä–Ω–æ —É–º–Ω–æ–∂–∞–µ—Ç—Å—è –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥ –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ $\\mathbf{M}_i$, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Å–∫–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ $r_{i, t}$ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –∞–π—Ç–µ–º–æ–≤.\n",
        "\n",
        "\n",
        "### ü§î **–ß—Ç–æ –ø–æ–¥–∞—ë—Ç—Å—è –Ω–∞ –≤—Ö–æ–¥?**\n",
        "–ù–∞ –≤—Ö–æ–¥ SASRec –ø–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏—Ö $|S^u|$ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n",
        "\n",
        "$$\\Large{S^u = \\left( S^u_1, S^u_2, \\dots, S^u_{|S^u|} \\right)},$$\n",
        "–≥–¥–µ $S^u_t$ - –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±—ä–µ–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–∏–ª—å–º–∞ –∏–ª–∏ —Ç–æ–≤–∞—Ä–∞), —Å –∫–æ—Ç–æ—Ä—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å $u$ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞–ª –≤ –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ $t$.\n",
        "\n",
        "\n",
        "### ü§∑‚Äç‚ôÄÔ∏è **–ß—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º?**\n",
        "–ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –æ–±—ä–µ–∫—Ç –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –§–æ—Ä–º–∞–ª—å–Ω–æ, –¥–ª—è –∫–∞–∂–¥–æ–≥–æ $t$ –æ–Ω–∞ –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ $(S^u_1, ..., S^u_{t-1})$ –∏ –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å $S^u_t$.\n",
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ $i$ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è —Å–∫–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ $r_{i, t}$ - –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —Ç–æ–≥–æ, –Ω–∞—Å–∫–æ–ª—å–∫–æ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –æ–±—ä–µ–∫—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –±—ã—Ç—å —Å–ª–µ–¥—É—é—â–∏–º –≤ –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ $t$:\n",
        "\n",
        "$$\\Large{r_{i, t} = \\langle F_t^{l}, M_i \\rangle},$$\n",
        "\n",
        "–≥–¥–µ $\\mathbf{F}_t^{l}$ - –≤—ã—Ö–æ–¥ l-–≥–æ —Å–ª–æ—è —ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏ $t$, –∞ $\\mathbf{M}_i$ - —ç–º–±–µ–¥–¥–∏–Ω–≥ –æ–±—ä–µ–∫—Ç–∞ $i$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teZUPalhfjjW"
      },
      "source": [
        "## üöÄ Task 2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è SASRecBackbone –∏ SASRecModel (2 –±–∞–ª–ª–∞)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZUbLAOcfjjW"
      },
      "source": [
        "### üîß –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —É—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nERZSUxZfjjW"
      },
      "source": [
        "1Ô∏è‚É£ –ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞—ë—Ç –º–∞—Å–∫—É –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π. –ú–∞—Å–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±—É–ª–µ–≤—ã–º —Ç–µ–Ω–∑–æ—Ä–æ–º —Ñ–æ—Ä–º—ã `(batch_size, max_seq_len)`, –≥–¥–µ `True` –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç –≤–∞–ª–∏–¥–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –∞ `False` ‚Äî –ø–∞–¥–¥–∏–Ω–≥."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMfcgNCdfjjW"
      },
      "outputs": [],
      "source": [
        "def get_mask(lengths: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Creates a boolean mask for variable-length sequences.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of shape (batch_size,) containing the actual length of each sequence\n",
        "        in the batch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        Boolean mask of shape (batch_size, max_seq_len) where True indicates a valid\n",
        "        element and False indicates padding. Can be used directly in attention masks\n",
        "        or for selective loss computation.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> lengths = torch.tensor([3, 5, 2])\n",
        "    >>> mask = get_mask(lengths)\n",
        "    >>> mask\n",
        "    tensor([[ True,  True,  True, False, False],\n",
        "            [ True,  True,  True,  True,  True],\n",
        "            [ True,  True, False, False, False]])\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybJ8TwvrfjjW"
      },
      "outputs": [],
      "source": [
        "def test_get_mask():\n",
        "    lengths = torch.tensor([3, 5, 2])\n",
        "    mask = get_mask(lengths)\n",
        "\n",
        "    assert mask.shape == (3, 5), f'–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞: {mask.shape}'\n",
        "    assert mask.dtype == torch.bool, f'–î–æ–ª–∂–µ–Ω –±—ã—Ç—å bool: {mask.dtype}'\n",
        "\n",
        "    assert (mask.sum(dim=1) == lengths).all(), '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ True != lengths'\n",
        "\n",
        "    expected = torch.tensor([\n",
        "        [True, True, True, False, False],\n",
        "        [True, True, True, True, True],\n",
        "        [True, True, False, False, False]\n",
        "    ])\n",
        "    assert torch.equal(mask, expected), f'–ù–µ–≤–µ—Ä–Ω–∞—è –º–∞—Å–∫–∞:\\n{mask}'\n",
        "\n",
        "    print('‚úÖ test_get_mask: OK')\n",
        "\n",
        "test_get_mask()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoUfilCVfjjW"
      },
      "source": [
        "2Ô∏è‚É£ –ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞–ª–∏–¥–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –∏–∑ –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ `flatten` –±–∞—Ç—á–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRNReP0SfjjW"
      },
      "outputs": [],
      "source": [
        "def get_last(data: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Extracts the last valid element from each sequence in a flattened batch.\n",
        "\n",
        "    Given a flattened tensor of concatenated sequences and their lengths, extracts\n",
        "    the final element of each sequence. Useful for obtaining the last hidden state\n",
        "    or final prediction from variable-length sequences without padding overhead.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : torch.Tensor\n",
        "        Tensor of shape (total_elements, ...) containing flattened sequences concatenated\n",
        "        sequentially. For example: [seq1_embedding1, seq1_embedding2, seq2_embedding1, seq2_embedding2, seq2_embedding3, ...]\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of shape (batch_size,) containing the length of each sequence.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        Tensor of shape (batch_size, ...) containing the last elements of each sequence.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> data = torch.tensor([1, 2, 3, 4, 5, 6])  # 3 sequences: [1,2], [3,4,5], [6]\n",
        "    >>> lengths = torch.tensor([2, 3, 1])\n",
        "    >>> get_last(data, lengths)\n",
        "    tensor([2, 5, 6])\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYzftd_ufjjW"
      },
      "outputs": [],
      "source": [
        "def test_get_last():\n",
        "    data = torch.tensor([1, 2, 3, 4, 5, 6])  # [1,2], [3,4,5], [6]\n",
        "    lengths = torch.tensor([2, 3, 1])\n",
        "    result = get_last(data, lengths)\n",
        "    assert torch.equal(result, torch.tensor([2, 5, 6])), f'–ù–µ–≤–µ—Ä–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}'\n",
        "\n",
        "    data_2d = torch.tensor([[1., 2.], [3., 4.], [5., 6.], [7., 8.], [9., 10.]])\n",
        "    lengths_2d = torch.tensor([2, 3])\n",
        "    result_2d = get_last(data_2d, lengths_2d)\n",
        "    expected_2d = torch.tensor([[3., 4.], [9., 10.]])\n",
        "    assert torch.equal(result_2d, expected_2d), f'–ù–µ–≤–µ—Ä–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è 2D: {result_2d}'\n",
        "\n",
        "    data_ones = torch.tensor([10, 20, 30])\n",
        "    lengths_ones = torch.tensor([1, 1, 1])\n",
        "    assert torch.equal(get_last(data_ones, lengths_ones), torch.tensor([10, 20, 30])), \\\n",
        "        '–ù–µ–≤–µ—Ä–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –µ–¥–∏–Ω–∏—á–Ω—ã—Ö –¥–ª–∏–Ω'\n",
        "\n",
        "    print('‚úÖ test_get_last: OK')\n",
        "\n",
        "test_get_last()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4EkjjahfjjW"
      },
      "source": [
        "3Ô∏è‚É£ –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–≥–ª–∞–∂–µ–Ω–Ω—ã–π –±–∞—Ç—á –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã –≤ padded —Ç–µ–Ω–∑–æ—Ä."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw5Cd49AfjjW"
      },
      "outputs": [],
      "source": [
        "def create_masked_tensor(data: torch.Tensor, lengths: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Converts a batch of variable-length sequences into a padded tensor and corresponding mask.\n",
        "\n",
        "    Transforms a flattened concatenation of sequences into a padded 2D (or 3D for embeddings)\n",
        "    tensor with right-padding zeros, along with a boolean mask indicating valid positions.\n",
        "    This function is the inverse of the collate operation and prepares data for models\n",
        "    that require fixed-size inputs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : torch.Tensor\n",
        "        Input tensor containing flattened sequences:\n",
        "        - For indices: shape (total_elements,) of dtype long\n",
        "        - For embeddings: shape (total_elements, embedding_dim)\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of sequence lengths, shape (batch_size,). Specifies the actual length\n",
        "        of each sequence before padding.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[torch.Tensor, torch.Tensor]\n",
        "        - padded_tensor: Padded tensor of shape:\n",
        "            - (batch_size, max_seq_len) for indices\n",
        "            - (batch_size, max_seq_len, embedding_dim) for embeddings\n",
        "            Shorter sequences are right-padded with zeros.\n",
        "        - mask: Boolean mask of shape (batch_size, max_seq_len) where True indicates\n",
        "            valid elements and False indicates padding. Can be used in attention or loss computation.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> data = torch.tensor([1, 2, 3, 4, 5, 6])  # sequences: [1,2], [3,4,5], [6]\n",
        "    >>> lengths = torch.tensor([2, 3, 1])\n",
        "    >>> padded, mask = create_masked_tensor(data, lengths)\n",
        "    >>> padded\n",
        "    tensor([[1, 2, 0],\n",
        "            [3, 4, 5],\n",
        "            [6, 0, 0]])\n",
        "    >>> mask\n",
        "    tensor([[ True,  True, False],\n",
        "            [ True,  True,  True],\n",
        "            [ True, False, False]])\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQOdDbN2fjjW"
      },
      "outputs": [],
      "source": [
        "def test_create_masked_tensor():\n",
        "    data = torch.tensor([1, 2, 3, 4, 5, 6])\n",
        "    lengths = torch.tensor([2, 3, 1])\n",
        "    padded, mask = create_masked_tensor(data, lengths)\n",
        "\n",
        "    expected_padded = torch.tensor([[1, 2, 0], [3, 4, 5], [6, 0, 0]])\n",
        "    expected_mask = torch.tensor([[True, True, False], [True, True, True], [True, False, False]])\n",
        "\n",
        "    assert torch.equal(padded, expected_padded), f'–ù–µ–≤–µ—Ä–Ω—ã–π padded:\\n{padded}'\n",
        "    assert torch.equal(mask, expected_mask), f'–ù–µ–≤–µ—Ä–Ω–∞—è mask:\\n{mask}'\n",
        "    assert (padded[~mask] == 0).all(), '–ü–∞–¥–¥–∏–Ω–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω—É–ª—è–º–∏'\n",
        "    assert (mask.sum(dim=1) == lengths).all(), '–°—É–º–º–∞ True != lengths'\n",
        "\n",
        "    data_2d = torch.randn(5, 4)  # 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤, dim=4\n",
        "    lengths_2d = torch.tensor([2, 3])\n",
        "    padded_2d, mask_2d = create_masked_tensor(data_2d, lengths_2d)\n",
        "\n",
        "    assert padded_2d.shape == (2, 3, 4), f'–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞ 2D: {padded_2d.shape}'\n",
        "    assert (padded_2d[~mask_2d] == 0).all(), '–ü–∞–¥–¥–∏–Ω–≥ 2D –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω—É–ª—è–º–∏'\n",
        "\n",
        "    print('‚úÖ test_create_masked_tensor: OK')\n",
        "\n",
        "test_create_masked_tensor()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i0d_HVMfjjW"
      },
      "source": [
        "### üèóÔ∏è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iREI-H4-fjjW"
      },
      "source": [
        "4Ô∏è‚É£  –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–ª–∞—Å—Å `SASRecBackbone`, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "–í —ç—Ç–æ–π –∑–∞–¥–∞—á–µ –≤—ã —Ä–µ–∞–ª–∏–∑—É–µ—Ç–µ —Ç–æ–ª—å–∫–æ backbone SASRec ‚Äî —á–∞—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –ø–æ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π $F_t^l$ –¥–ª—è –≤—Å–µ—Ö –ø–æ–∑–∏—Ü–∏–π. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä / —Å–ª–æ–π, —Å—á–∏—Ç–∞—é—â–∏–π —Å–∫–æ—Ä $r_{i, t}$, –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ.\n",
        "\n",
        "–ß—Ç–æ –ø–æ–¥–∞—ë—Ç—Å—è –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏?\n",
        "\n",
        "–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–µ –∏–∑ `YambdaDataset` –∏ `collate_fn` –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ flatten —Ñ–æ—Ä–º–∞—Ç –∏ –∑–∞—Ç–µ–º –≤ padded –±–∞—Ç—á–∏. –ù–∞ –≤—Ö–æ–¥ `SASRecBackbone.forward` –ø—Ä–∏—Ö–æ–¥–∏—Ç —Å–ª–æ–≤–∞—Ä—å:\n",
        "\n",
        "- `inputs['item_id']` ‚Äî —Ç–µ–Ω–∑–æ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏—Å—Ç–æ—Ä–∏—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, `shape: (total_elements,)`\n",
        "- `inputs['positions']` ‚Äî —Ç–µ–Ω–∑–æ—Ä –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ $(0, 1, 2, \\dots)$, `shape: (total_elements,)`\n",
        "- `inputs['lengths']` ‚Äî –¥–ª–∏–Ω—ã –∏—Å—Ç–æ—Ä–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –±–∞—Ç—á–µ, `shape: (batch_size,)`\n",
        "\n",
        "–≠—Ç–∏ —Ç–µ–Ω–∑–æ—Ä—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º $S^u$, —É–∂–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º –∏ –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–º –¥–æ `max_seq_len`.\n",
        "\n",
        "–ß—Ç–æ –¥–æ–ª–∂–Ω–∞ –¥–µ–ª–∞—Ç—å –º–æ–¥–µ–ª—å?\n",
        "1) –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å `item_id` –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –ø—Ä–∏ –ø–æ–º–æ—â–∏ `nn.Embedding`\n",
        "2) –î–æ–±–∞–≤–∏—Ç—å –∫ –Ω–∏–º –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å —Ä–∞–∑–ª–∏—á–∞–ª–∞ –ø–æ—Ä—è–¥–æ–∫ —Å–æ–±—ã—Ç–∏–π\n",
        "3) –° –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `create_masked_tensor` –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å flatten –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ padded –±–∞—Ç—á\n",
        "4) –ü–æ—Å—Ç—Ä–æ–∏—Ç—å causal `mask`, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–ø—Ä–µ—â–∞–µ—Ç –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ —Å–º–æ—Ç—Ä–µ—Ç—å –≤ –±—É–¥—É—â–µ–µ\n",
        "5) –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –±–∞—Ç—á —á–µ—Ä–µ–∑ `nn.TransformerEncoder`\n",
        "6) –í–µ—Ä–Ω—É—Ç—å –≤ –≤—ã—Ö–æ–¥–µ —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –ø–æ–∑–∏—Ü–∏–π –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π. –ò–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç —Ç–µ–Ω–∑–æ—Ä –¥–∞–ª—å—à–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å–∫–æ—Ä–æ–≤ $r_{i, t}$ –∏ —Ü–µ–ª–µ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydP4vkiFfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecBackbone(nn.Module):\n",
        "    \"\"\"\n",
        "    Self-Attentive Sequential Recommendation (SASRec) backbone architecture.\n",
        "\n",
        "    Implements the core transformer-based model for sequential recommendation that captures\n",
        "    user preferences by attending to their historical interactions. The model uses self-attention\n",
        "    mechanisms with causal masking to ensure autoregressive generation: each position can only\n",
        "    attend to previous positions.\n",
        "\n",
        "    Architecture:\n",
        "    1. Embedding layer: converts item IDs to dense vectors\n",
        "    2. Positional encoding: adds position information to embeddings\n",
        "    3. Transformer encoder: multi-head self-attention with causal masking\n",
        "    4. Output: encoder representations for downstream tasks\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_items : int\n",
        "        Total number of unique items in the catalog. Used for embedding table size.\n",
        "    embedding_dim : int, optional\n",
        "        Dimension of item and position embeddings.\n",
        "    num_heads : int, optional\n",
        "        Number of attention heads in transformer.\n",
        "    max_seq_len : int, optional\n",
        "        Maximum sequence length for positional embeddings.\n",
        "    dropout_rate : float, optional\n",
        "        Dropout probability for regularization.\n",
        "    num_transformer_layers : int, optional\n",
        "        Number of transformer encoder layers.\n",
        "\n",
        "    Input Format\n",
        "    -----------\n",
        "    inputs : Dict[str, torch.Tensor]\n",
        "        Dictionary containing:\n",
        "        - 'item_id': Flattened item indices, shape (total_elements,)\n",
        "        - 'positions': Positional indices, shape (total_elements,)\n",
        "        - 'lengths': Actual sequence lengths for each sample, shape (batch_size,)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, torch.Tensor]\n",
        "        Dictionary containing:\n",
        "        - 'encoder_output': Transformer encoder output, shape (total_valid_elements, embedding_dim)\n",
        "            Contains only non-padded representations extracted using the mask.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> model = SASRecBackbone(num_items=10000, embedding_dim=64, num_heads=2)\n",
        "    >>> inputs = {\n",
        "    ...     'item_id': torch.tensor([1, 2, 3, 4, 5, 6]),\n",
        "    ...     'positions': torch.tensor([0, 1, 2, 0, 1, 2]),\n",
        "    ...     'lengths': torch.tensor([3, 3])\n",
        "    ... }\n",
        "    >>> output = model(inputs)\n",
        "    >>> output['encoder_output'].shape\n",
        "    torch.Size([6, 64])\n",
        "\n",
        "    Note\n",
        "    ----\n",
        "    - Uses causal masking to prevent looking into future\n",
        "    - Handles variable-length sequences via padding and masking\n",
        "    - Position embeddings are added additively to item embeddings\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_items: int,\n",
        "            embedding_dim: int = 64,\n",
        "            num_heads: int = 2,\n",
        "            max_seq_len: int = 512,\n",
        "            dropout_rate: float = 0.2,\n",
        "            num_transformer_layers: int = 2,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.item_embeddings = ...  # TODO: your code here\n",
        "        self.position_embeddings = ...  # TODO: your code here\n",
        "\n",
        "        encoder_layer = ...  # TODO: your code here\n",
        "        self.transformer_encoder = ...  # TODO: your code here\n",
        "\n",
        "    def forward(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass through the SASRec model.\n",
        "\n",
        "        Processes flattened input sequences through embedding, padding, and transformer\n",
        "        encoder with causal masking to produce contextual representations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : Dict[str, torch.Tensor]\n",
        "            Input dictionary containing:\n",
        "            - 'item_id': Flattened item indices, shape (total_elements,)\n",
        "            - 'positions': Positional indices [0, 1, 2, ...], shape (total_elements,)\n",
        "            - 'lengths': Sequence lengths, shape (batch_size,)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, torch.Tensor]\n",
        "            Output dictionary containing:\n",
        "            - 'encoder_output': Valid (non-padded) encoder representations,\n",
        "              shape (total_elements, embedding_dim)\n",
        "\n",
        "        Processing Steps\n",
        "        ----------------\n",
        "        1. Embed items and positions\n",
        "        2. Add position embeddings to item embeddings\n",
        "        3. Convert to padded format with mask\n",
        "        4. Create causal mask for autoregressive attention\n",
        "        5. Pass through transformer encoder with causal and padding masks\n",
        "        6. Extract only valid positions using mask\n",
        "        \"\"\"\n",
        "        lengths = inputs['lengths']\n",
        "\n",
        "        embeddings = ...  # TODO: your code here\n",
        "        position_embeddings = ...  # TODO: your code here\n",
        "        embeddings = embeddings + position_embeddings  # (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        embeddings, mask = create_masked_tensor(\n",
        "            data=embeddings, lengths=lengths\n",
        "        )  # (batch_size, seq_len, embedding_dim), (batch_size, seq_len)\n",
        "\n",
        "        encoder_output = ...  # TODO: your code here\n",
        "\n",
        "        return {\n",
        "            'encoder_output': encoder_output\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf4ueb6WfjjX"
      },
      "outputs": [],
      "source": [
        "def test_sasrec_backbone():\n",
        "    model = SASRecBackbone(num_items=1000, embedding_dim=32, num_heads=2)\n",
        "    model.eval()\n",
        "\n",
        "    assert model.item_embeddings.num_embeddings == 1000, '–ù–µ–≤–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä item_embeddings'\n",
        "    assert model.item_embeddings.embedding_dim == 32, '–ù–µ–≤–µ—Ä–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤'\n",
        "\n",
        "    inputs = {\n",
        "        'item_id': torch.tensor([1, 2, 3, 4, 5]),\n",
        "        'positions': torch.tensor([0, 1, 2, 0, 1]),\n",
        "        'lengths': torch.tensor([3, 2])\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(inputs)\n",
        "\n",
        "    assert output['encoder_output'].shape == (5, 32), \\\n",
        "        f'–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞: {output['encoder_output'].shape}'\n",
        "    assert not torch.isnan(output['encoder_output']).any(), '–í—ã—Ö–æ–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç NaN'\n",
        "\n",
        "    print('‚úÖ test_sasrec_backbone: OK')\n",
        "\n",
        "\n",
        "test_sasrec_backbone()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv273oFrfjjX"
      },
      "source": [
        "5Ô∏è‚É£ –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–ª–∞—Å—Å `SASRecModel`, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç `backbone` —Å –ª–æ–≥–∏–∫–æ–π –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏.\n",
        "\n",
        "–ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –¥–≤—É—Ö —Ä–µ–∂–∏–º–∞—Ö:\n",
        "\n",
        "1) –†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è (`self.training == True`):\n",
        "    - –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —á–µ—Ä–µ–∑ `backbone` —ç–Ω–∫–æ–¥–µ—Ä\n",
        "    - –í—ã–∑–æ–≤–∏—Ç–µ –º–µ—Ç–æ–¥ `compute_loss` –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ (–º—ã —Ä–µ–∞–ª–∏–∑—É–µ–º –µ–≥–æ –ø–æ–∑–∂–µ)\n",
        "    - –í–µ—Ä–Ω–∏—Ç–µ —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–æ–º `'loss'`\n",
        "\n",
        "2) –†–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏/—Ç–µ—Å—Ç–∞ (`self.training == False`):\n",
        "- –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —á–µ—Ä–µ–∑ `backbone` —ç–Ω–∫–æ–¥–µ—Ä\n",
        "- –° –ø–æ–º–æ—â—å—é `get_last()` –∏–∑–≤–ª–µ–∫–∏—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
        "- –ò–∑–≤–ª–µ–∫–∏—Ç–µ —Ü–µ–ª–µ–≤–æ–π (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π) –∞–π—Ç–µ–º –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
        "- –í—ã—á–∏—Å–ª–∏—Ç–µ —Å–∫–æ—Ä—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –∞–π—Ç–µ–º–æ–≤ –∫–∞—Ç–∞–ª–æ–≥–∞\n",
        "- –í—ã—á–∏—Å–ª–∏—Ç–µ —Å–∫–æ—Ä —Å —Ü–µ–ª–µ–≤—ã–º –∞–π—Ç–µ–º–æ–º –æ—Ç–¥–µ–ª—å–Ω–æ\n",
        "- –í–µ—Ä–Ω–∏—Ç–µ –æ–±–∞ —Ç–∏–ø–∞ —Å–∫–æ—Ä–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy3n8LNQfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Complete SASRec recommendation model combining backbone encoder with training and inference logic.\n",
        "\n",
        "    This model wraps the SASRecBackbone encoder and implements two distinct forward passes:\n",
        "\n",
        "    - Training mode: processes user sequences through the backbone and computes a loss value\n",
        "      for parameter optimization.\n",
        "\n",
        "    - Evaluation mode (validation/test): uses the backbone to encode user histories,\n",
        "      then computes relevance scores for all items in the catalog. For each user,\n",
        "      the model produces scores r_i = <F^l, M_i> where F^l is the last encoder\n",
        "      output for that user and M_i is the embedding of item i.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The transformer encoder backbone that produces contextualized representations\n",
        "        from user interaction sequences.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.init_weights(0.02)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def init_weights(self, initializer_range: float) -> None:\n",
        "        \"\"\"\n",
        "        Initializes model weights using truncated normal distribution.\n",
        "\n",
        "        Strategy:\n",
        "        - Weight matrices: truncated normal with std=initializer_range\n",
        "        - LayerNorm weights: ones (identity)\n",
        "        - Biases: zeros\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        initializer_range : float\n",
        "            Standard deviation for truncated normal initialization.\n",
        "        \"\"\"\n",
        "        for key, value in self.named_parameters():\n",
        "            if 'weight' in key:\n",
        "                if 'norm' in key:\n",
        "                    nn.init.ones_(value.data)\n",
        "                else:\n",
        "                    nn.init.trunc_normal_(\n",
        "                        value.data, std=initializer_range, a=-2 * initializer_range, b=2 * initializer_range\n",
        "                    )\n",
        "            else:\n",
        "                assert 'bias' in key\n",
        "                nn.init.zeros_(value.data)\n",
        "\n",
        "    def compute_loss(self, inputs: Dict, backbone_output: Dict[str, torch.Tensor]) -> Dict:\n",
        "        # DO NOT CHANGE THIS FUNCTION HERE\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, inputs: Dict):\n",
        "        \"\"\"\n",
        "        Forward pass of the SASRec model with mode-dependent behavior.\n",
        "\n",
        "        During training: computes and returns loss.\n",
        "        During evaluation: computes and returns ranking scores for all items.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : Dict\n",
        "            Input batch dictionary with keys:\n",
        "            - 'history': encoded user sequence (processed by YambdaDataset)\n",
        "              containing 'item_id', 'positions', 'lengths'\n",
        "            - 'labels': ground truth next items\n",
        "              containing 'item_id', 'lengths'\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            - If training (self.training == True):\n",
        "              {'loss': scalar tensor}\n",
        "\n",
        "            - If evaluating (self.training == False):\n",
        "              {\n",
        "                'all_scores': (batch_size, num_items) relevance scores for all items,\n",
        "                'positive_scores': (batch_size,) scores for ground truth items\n",
        "              }\n",
        "        \"\"\"\n",
        "        backbone_outputs = self.backbone(inputs['history'])\n",
        "\n",
        "        if self.training:\n",
        "            # –û–±—É—á–µ–Ω–∏–µ\n",
        "            return {\n",
        "                'loss': self.compute_loss(inputs, backbone_outputs)\n",
        "            }\n",
        "        else:\n",
        "            # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
        "            last_embeddings = ...  # TODO: your code here\n",
        "            last_labels = ...  # TODO: your code here\n",
        "\n",
        "            last_labels_embeddings = ... # TODO: your code here\n",
        "            all_item_embeddings = ... # TODO: your code here\n",
        "\n",
        "            all_scores = ... # TODO: your code here\n",
        "            positive_score = ... # TODO: your code here\n",
        "\n",
        "            return {\n",
        "                'all_scores': all_scores,\n",
        "                'positive_scores': positive_score,\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4uGUwKqfjjX"
      },
      "outputs": [],
      "source": [
        "def test_sasrec_model():\n",
        "    backbone = SASRecBackbone(num_items=100, embedding_dim=32, num_heads=2)\n",
        "    model = SASRecModel(backbone)\n",
        "\n",
        "    inputs = {\n",
        "        'history': {\n",
        "            'item_id': torch.tensor([1, 2, 3, 4, 5]),\n",
        "            'positions': torch.tensor([0, 1, 2, 0, 1]),\n",
        "            'lengths': torch.tensor([3, 2])\n",
        "        },\n",
        "        'labels': {'item_id': torch.tensor([2, 3, 4, 5, 6])}\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(inputs)\n",
        "\n",
        "    assert out['all_scores'].shape == (2, 100), f'–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞ all_scores: {out['all_scores'].shape}'\n",
        "    assert out['positive_scores'].shape == (2,), f'–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞ positive_scores: {out['positive_scores'].shape}'\n",
        "    assert not torch.isnan(out['all_scores']).any(), 'all_scores —Å–æ–¥–µ—Ä–∂–∏—Ç NaN'\n",
        "\n",
        "    model.train()\n",
        "    try:\n",
        "        model(inputs)\n",
        "        assert False, 'compute_loss –¥–æ–ª–∂–µ–Ω –≤—ã–±—Ä–æ—Å–∏—Ç—å NotImplementedError'\n",
        "    except NotImplementedError:\n",
        "        pass\n",
        "\n",
        "    print('‚úÖ test_sasrec_model: OK')\n",
        "\n",
        "\n",
        "test_sasrec_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTeO4wZ9fjjX"
      },
      "source": [
        "# üíª –†–µ–∞–ª–∏–∑—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –æ–±—É—á–µ–Ω–∏—è SASRec'–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCAyAtDBfjjX"
      },
      "source": [
        "## ü§ì Task 3. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ SASRec –∏–∑ —Å—Ç–∞—Ç—å–∏ (1 –±–∞–ª–ª)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dBIuDwvfjjX"
      },
      "source": [
        "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ `SASRec` —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `BinaryCrossEntropy` –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_UnlxuNfjjX"
      },
      "source": [
        "–í –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–ª–æ—Å—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å BCE (Binary Cross Entropy):\n",
        "\n",
        "$$\\Large{\\mathcal{L}_{Original} = - \\sum_{S^u \\in S} \\sum_{t \\in [1, 2, \\dots, |S^u| - 1]} \\Bigg[ \\log \\sigma \\left( r_{S^u_{t+1}, t} \\right)  + \\sum_{j \\notin S^u} \\log \\left( 1 - \\sigma \\left( r_{j,t} \\right)   \\right)} \\Bigg],$$\n",
        "\n",
        "–≥–¥–µ $\\sigma(r_{i,t})$ - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–≥–æ, —á—Ç–æ –∞–π—Ç–µ–º $i$ –±—É–¥–µ—Ç —Å–ª–µ–¥—É—é—â–∏–º –≤ –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ $t$, –∞ $\\sigma$ - —Å–∏–≥–º–æ–∏–¥–∞.\n",
        "\n",
        "$\\color{red}{\\text{–ù–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Å—É–º–º—ã –Ω–µ—Ç, –≤ —Å—Ç–∞—Ç—å–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–¥–∏–Ω –Ω–µ–≥–∞—Ç–∏–≤ –Ω–∞ –æ–¥–∏–Ω –ø–æ–∑–∏—Ç–∏–≤}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WsmUksYfjjX"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvJmVgHNfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecReal(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec model trained with Binary Cross-Entropy loss (negative sampling).\n",
        "\n",
        "    For each position t in a user sequence, the model learns to distinguish between:\n",
        "    - Positive: the ground-truth next item S^u_t (label = 1)\n",
        "    - Negative: a randomly sampled item from the catalog (label = 0)\n",
        "\n",
        "    The loss is computed as:\n",
        "        L = BCE(scores, labels)\n",
        "    where scores are computed as dot products between query embeddings (from backbone)\n",
        "    and item embeddings (positive and negative).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Negative sampling is done uniformly at random from the entire item catalog.\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss(self, inputs: Dict, backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ysm8Rd5fjjX"
      },
      "source": [
        "## üòá Task 4. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è SASRec —á–µ—Ä–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ in-batch –Ω–µ–≥–∞—Ç–∏–≤–æ–≤ (1 –±–∞–ª–ª)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKtZq_mQfjjY"
      },
      "source": [
        "–í—Å–µ –∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π —Å–æ—Ñ—Ç–º–∞–∫—Å –Ω–µ –≤—Å–µ–≥–¥–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω—ã–º –∏ —Ä–∞–Ω–¥–æ–º–Ω–æ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –∏–∑ –≤—Å–µ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç—Ä–∏–≤–∏–∞–ª—å–Ω–æ. –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–µ—à–∏—Ç—å —ç—Ç–∏ –ø—Ä–æ–±–ª–µ–º—ã –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –º—ã –ø–æ–ª—É—á–∞–µ–º –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –≤ –±–∞—Ç—á–µ.\n",
        "\n",
        "$$\\Large{\\mathcal{L}_{\\text{in batch}} = - \\sum_{S^u \\in S} \\sum_{t \\in [1, 2, \\dots, n]}  \\Bigg[  - \\log \\left( \\frac{e^{r_{S^u_{t+1}, t}}}{e^{r_{S^u_{t+1}, t}} + \\sum_{d \\in Sample(B, k)}{e^{r_{d, t}}}} \\right) \\Bigg]},$$\n",
        "\n",
        "–≥–¥–µ $k$ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–≥–∞—Ç–∏–≤–æ–≤, –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–º–ø–ª–∞, $B$ - –Ω–∞–±–æ—Ä –∏–∑ –≤—Å–µ—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ –±–∞—Ç—á–µ.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVxgmMdlfjjY"
      },
      "source": [
        "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –≤–µ—Ä—Å–∏—é `SASRec`, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç in-batch negative sampling –≤–º–µ—Å—Ç–æ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞. –≠—Ç–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —á–∞—Å—Ç–æ –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞, —Ç–∞–∫ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ, —É–∂–µ –Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è –≤ –ø–∞–º—è—Ç–∏, –∏ –æ–±—ã—á–Ω–æ –¥–∞—ë—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–ª–∞–≥–æ–¥–∞—Ä—è –±–æ–ª–µ–µ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã–º –Ω–µ–≥–∞—Ç–∏–≤–∞–º.\n",
        "\n",
        "–ò–¥–µ—è:\n",
        "–í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã —Å–ª—É—á–∞–π–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∞–π—Ç–µ–º—ã –∏–∑ –≤—Å–µ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞, –º—ã –≤—ã–±–∏—Ä–∞–µ–º –∏—Ö –∏–∑ –∞–π—Ç–µ–º–æ–≤, —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤ —Ç–µ–∫—É—â–µ–º –±–∞—Ç—á–µ (—Ç–æ –µ—Å—Ç—å –∏–∑ —Ü–µ–ª–µ–≤—ã—Ö –∞–π—Ç–µ–º–æ–≤ –¥—Ä—É–≥–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –±–∞—Ç—á–µ). –≠—Ç–æ –¥–∞—ë—Ç –Ω–∞–º \"—Ç—Ä—É–¥–Ω–µ–µ\" –Ω–µ–≥–∞—Ç–∏–≤—ã ‚Äî –æ–Ω–∏ –±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∞–π—Ç–µ–º—ã, —á–µ–º —Å–æ–≤—Å–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyF-pPs6fjjY"
      },
      "outputs": [],
      "source": [
        "class SASRecInBatch(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec model trained with using in-batch negative sampling.\n",
        "\n",
        "    For each position t in a user sequence, the model learns to distinguish:\n",
        "    - Positive: the ground-truth next item S^u_t\n",
        "    - Negatives: `num_negatives` random items sampled from the given batch of target items\n",
        "\n",
        "    This formulation is equivalent to multi-class classification where the model\n",
        "    finds one positive among (1 + num_negatives) candidates.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "    num_negatives : int\n",
        "        Number of negative samples per positive example.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - In-batch negatives are sampled uniformly from batch target items.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "            num_negatives: int\n",
        "        ) -> None:\n",
        "        super().__init__(backbone)\n",
        "        self.num_negatives = num_negatives\n",
        "\n",
        "    def compute_loss(self, inputs: Dict[str, torch.Tensor], backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrb3dln_fjjY"
      },
      "source": [
        "## ü§© Task 5. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è SASRec —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º log-q –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –≤ in-batch –ø–æ–¥—Ö–æ–¥ (2 –±–∞–ª–ª–∞)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5KZ_yrfjjY"
      },
      "source": [
        "üò¢ –ü—Ä–æ–±–ª–µ–º–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø–æ–ª—Ö–æ–¥–∞: –°–º–µ—â–µ–Ω–∏–µ In-Batch Negative Sampling\n",
        "\n",
        "–ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ in-batch negative sampling –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã–±–∏—Ä–∞—é—Ç—Å—è –∏–∑ —Ü–µ–ª–µ–≤—ã—Ö –∞–π—Ç–µ–º–æ–≤ –±–∞—Ç—á–∞. –û–¥–Ω–∞–∫–æ —ç—Ç–∏ –∞–π—Ç–µ–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ ‚Äî –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞–π—Ç–µ–º—ã –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –±–∞—Ç—á–µ —á–∞—â–µ, —á–µ–º —Ä–µ–¥–∫–∏–µ (long-tail distribution). –≠—Ç–æ –≤–≤–æ–¥–∏—Ç —Å–º–µ—â–µ–Ω–∏–µ: –º–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞–π—Ç–µ–º—ã —á–∞—â–µ –∫–∞–∫ –Ω–µ–≥–∞—Ç–∏–≤—ã, —á—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –∏—Ö —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.\n",
        "\n",
        "–ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –∞–π—Ç–µ–º A –ø–æ–ø—É–ª—è—Ä–µ–Ω (—á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è), –æ–Ω —á–∞—Å—Ç–æ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã. –ú–æ–¥–µ–ª—å –Ω–∞—á–∏–Ω–∞–µ—Ç \"—Å–∏–ª—å–Ω–µ–µ –æ—Ç—Ç–∞–ª–∫–∏–≤–∞—Ç—å\" –µ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, –¥–∞–∂–µ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –≤—Å–µ–≥–¥–∞ –Ω—É–∂–Ω–æ. –≠—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∞–π—Ç–µ–º–æ–≤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3jtlmPRfjjY"
      },
      "source": [
        "‚≠ê –†–µ—à–µ–Ω–∏–µ: LogQ Correction\n",
        "\n",
        "LogQ correction –∫–æ–º–ø–µ–Ω—Å–∏—Ä—É–µ—Ç —ç—Ç–æ —Å–º–µ—â–µ–Ω–∏–µ, –≤—ã—á–∏—Ç–∞—è –∏–∑ —Å–∫–æ—Ä–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ –∞–π—Ç–µ–º–∞ –ª–æ–≥–∞—Ä–∏—Ñ–º –µ–≥–æ —á–∞—Å—Ç–æ—Ç—ã –≤ –±–∞—Ç—á–µ:\n",
        "\n",
        "$$r_{i, t}^{*} = r_{i, t} - \\log(Q(i)),$$\n",
        "\n",
        "–≥–¥–µ $\\large{Q(i) = \\frac{\\#i}{\\#all}}$ - –¥–æ–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π —Å –∞–π—Ç–µ–º–æ–º $i$.\n",
        "\n",
        "–≠—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–µ—Å–º–µ—â—ë–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–µ –∏—Å—Ç–∏–Ω–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –∞–π—Ç–µ–º–∞.\n",
        "\n",
        "–î–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è log-q –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –Ω–∞–º –Ω–∞–¥–æ –∏–∑–º–µ–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É –≤–µ—â—å: –Ω–∞–¥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–æ–≤\n",
        "\n",
        "–ï—Å–ª–∏ –≤–∞–º –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ —Ñ–æ—Ä–º—É–ª, —Å–æ–≤–µ—Ç—É—é –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —ç—Ç–∏ —Å—Ç–∞—Ç—å–∏:\n",
        "\n",
        "1. [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/)\n",
        "1. [Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval](https://arxiv.org/abs/2507.09331)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmdiuhBfjjY"
      },
      "source": [
        "–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é in-batch negative sampling —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–æ—Ö–æ–¥–∞ LogQ correction ‚Äî —Ç–µ—Ö–Ω–∏–∫–æ–π –¥–ª—è –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ —Å–º–µ—â–µ–Ω–∏—è, –≤–≤–æ–¥–∏–º–æ–≥–æ in-batch negative sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vYvaV5rfjjY"
      },
      "outputs": [],
      "source": [
        "def compute_item_statistics(dataset: YambdaDataset):\n",
        "    item_counts = Counter()\n",
        "    all_cnt = 0\n",
        "    idx = 0\n",
        "    while True:\n",
        "        try:\n",
        "            sample = dataset[idx]\n",
        "            for item_id in sample['labels']['item_id']:\n",
        "                item_counts[item_id] += 1\n",
        "                all_cnt += 1\n",
        "            idx += 1\n",
        "        except:\n",
        "            break\n",
        "\n",
        "    return item_counts, all_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtE783pYfjjY"
      },
      "outputs": [],
      "source": [
        "class SASRecInBatchWithLogQ(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec with in-batch negative sampling and LogQ bias correction.\n",
        "\n",
        "    When negative samples are drawn from a batch,\n",
        "    they follow the empirical distribution of the data (popular items\n",
        "    appear more frequently), which can bias the learned embeddings.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "    num_negatives : int\n",
        "        Number of negative samples per positive example (sampled from batch).\n",
        "    item_freqs : torch.Tensor\n",
        "        1D tensor of shape (num_items,) containing frequency/probability of each\n",
        "        item in the training data. Used for LogQ correction.\n",
        "        Example: item_freqs[i] = (count of item i) / (total items in dataset)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "            num_negatives: int,\n",
        "            item_freqs: torch.Tensor\n",
        "        ) -> None:\n",
        "        super().__init__(backbone=backbone)\n",
        "        self.num_negatives = num_negatives\n",
        "        self.register_buffer('item_freqs', item_freqs)\n",
        "\n",
        "    def apply_correction(self, scores: torch.Tensor, freqs: torch.Tensor) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, inputs: Dict[str, torch.Tensor], backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6n7z15PfjjY"
      },
      "source": [
        "## üéØ Task 6. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (1 –±–∞–ª–ª)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu-60hVBfjjY"
      },
      "source": [
        "–î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–Ω–∏–º–∞—Ç—å –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞—à–∞ –º–æ–¥–µ–ª—å, –Ω–∞–º –Ω—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å—Å—è —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–π –º—ã —Ö–æ—Ç–∏–º —Å—á–∏—Ç–∞—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–µ. –í —Ä–∞–º–∫–∞—Ö –¥–∞–Ω–Ω–æ–≥–æ —Å–µ–º–∏–Ω–∞—Ä–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏:\n",
        "\n",
        "$$\\text{HitRate@k} = \\frac{1}{|S|} \\sum_{S^u \\in S}{ \\mathbb{I} [ \\text{positive} \\in \\text{recommended}[:\\text{k}]] },$$\n",
        "\n",
        "$$\\text{DCG@k} = \\frac{1}{|S|}\\sum_{S^u \\in S}{}{\\sum_{i = 1}^{k} \\frac{\\mathbb{I} [ \\text{recommended}^u_i = \\text{positive} ] }{\\log_2(i + 1)}},$$\n",
        "\n",
        "$$\\text{Coverage@k} = \\frac{ \\bigcup_{S^u \\in S}{ \\bigcup_{i=1}^{k}{ \\text{recommended}^u_i}} }{|\\mathcal{I}|},$$\n",
        "\n",
        "–≥–¥–µ $\\text{positive}$ - —Å–ª–µ–¥—É—é—â–µ–µ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ, –∞ $\\text{recommended}$ - —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–∞—è –≤—ã–¥–∞—á–∞, —Å–ø–∏—Å–æ–∫ –∞–π–¥–∏—à–Ω–∏–∫–æ–≤ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π –ø–æ —É–±—ã–≤–∞–Ω–∏—é. $\\mathcal{I}$ - –≤–µ—Å—å –∫–∞—Ç–∞–ª–æ–≥ –∞–π—Ç–µ–º–æ–≤.\n",
        "\n",
        "–í–∞–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø–æ–∑–∏—Ç–∏–≤, —Ç–æ –¥–ª—è –Ω–∞—à–µ–≥–æ —Å–ª—É—á–∞—è $\\text{HitRate@k} = \\text{Recall@k}$ –∏ $\\text{DCG@k} = \\text{nDCG@k}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb7fEmVrfjjY"
      },
      "outputs": [],
      "source": [
        "def compute_hitrate(all_scores: torch.Tensor, positive_scores: torch.Tensor, k: int) -> List[float]:\n",
        "    \"\"\"\n",
        "    Computes Hit Rate@k for each sample in the batch.\n",
        "\n",
        "    Hit Rate measures whether the ground truth positive item appears in the top-k\n",
        "    ranked items. For each user, it's a binary metric: 1 if the positive item is\n",
        "    in top-k, 0 otherwise.\n",
        "\n",
        "    Hit Rate@k = 1 if rank(positive_item) < k, else 0\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    all_scores : torch.Tensor\n",
        "        Relevance scores for all items in the catalog, shape (batch_size, num_items).\n",
        "        Higher scores indicate higher relevance.\n",
        "    positive_scores : torch.Tensor\n",
        "        Relevance scores for the ground truth positive items (targets),\n",
        "        shape (batch_size,).\n",
        "    k : int\n",
        "        Cutoff for top-k evaluation. Typical values: 1, 5, 10, 20, 50, 100.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[float]\n",
        "        Hit Rate values for each sample in the batch, shape (batch_size,).\n",
        "        Each value is either 0.0 (miss) or 1.0 (hit).\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass\n",
        "\n",
        "\n",
        "def compute_dcg(all_scores: torch.Tensor, positive_scores: torch.Tensor, k: int) -> List[float]:\n",
        "    \"\"\"\n",
        "    Computes DCG@k for each sample in the batch.\n",
        "\n",
        "    DCG (Discounted Cumulative Gain) measures ranking quality with position discount.\n",
        "    For a single positive item at position p (0-indexed):\n",
        "        DCG@k = 1 / log2(p + 2) if p < k else 0\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    all_scores : torch.Tensor\n",
        "        Scores for all items, shape (batch_size, num_items).\n",
        "    positive_scores : torch.Tensor\n",
        "        Scores for the ground truth positive items, shape (batch_size,).\n",
        "    k : int\n",
        "        Cutoff for evaluation (top-k).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[float]\n",
        "        DCG@k values for each sample in the batch.\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass\n",
        "\n",
        "\n",
        "def compute_metrics(all_scores: torch.Tensor, positive_scores: torch.Tensor) -> Dict[str, float]:\n",
        "    return {\n",
        "        'dcg@10': compute_dcg(all_scores, positive_scores, k=10),\n",
        "        'dcg@100': compute_dcg(all_scores, positive_scores, k=100),\n",
        "        'dcg@1000': compute_dcg(all_scores, positive_scores, k=1000),\n",
        "\n",
        "        'hitrate@10': compute_hitrate(all_scores, positive_scores, k=10),\n",
        "        'hitrate@100': compute_hitrate(all_scores, positive_scores, k=100),\n",
        "        'hitrate@1000': compute_hitrate(all_scores, positive_scores, k=1000),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOdVHjr8fjjY"
      },
      "outputs": [],
      "source": [
        "def test_compute_hitrate():\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.9]), k=1) == [1.0]\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=1) == [0.0]\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=2) == [1.0]\n",
        "\n",
        "    all_scores = torch.tensor([[0.9, 0.5, 0.3], [0.9, 0.8, 0.7]])\n",
        "    positive = torch.tensor([0.9, 0.8])\n",
        "    assert compute_hitrate(all_scores, positive, k=2) == [1.0, 1.0]\n",
        "\n",
        "    print('‚úÖ test_compute_hitrate: OK')\n",
        "\n",
        "\n",
        "def test_compute_dcg():\n",
        "    import math\n",
        "\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.5]]), torch.tensor([0.9]), k=2)[0] - 1.0) < 1e-5\n",
        "\n",
        "    expected = 1.0 / math.log2(3)\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=2)[0] - expected) < 1e-5\n",
        "\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.8, 0.5]]), torch.tensor([0.5]), k=3)[0] - 0.5) < 1e-5\n",
        "\n",
        "    assert compute_dcg(torch.tensor([[0.9, 0.8, 0.7, 0.5]]), torch.tensor([0.5]), k=2)[0] == 0.0\n",
        "\n",
        "    print('‚úÖ test_compute_dcg: OK')\n",
        "\n",
        "\n",
        "test_compute_hitrate()\n",
        "test_compute_dcg()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNy5CVEXfjjY"
      },
      "source": [
        "# üî• –û–±—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfKzTo1fjjY"
      },
      "source": [
        "## üé∞ –í–∞–ª–∏–¥–∞—Ü–∏—è / —ç–≤–∞–ª –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3V_FSkPfjjY"
      },
      "outputs": [],
      "source": [
        "def evaluation(\n",
        "        dataloader: DataLoader,\n",
        "        model: SASRecModel,\n",
        "        device: str = 'cpu',\n",
        "        num_batches: Optional[int] = None\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    eval_metrics = defaultdict(list)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for idx, batch in tqdm(enumerate(dataloader)):\n",
        "        for key in batch:\n",
        "            if isinstance(batch[key], dict):\n",
        "                for sub_key in batch[key]:\n",
        "                    batch[key][sub_key] = batch[key][sub_key].to(device)\n",
        "            else:\n",
        "                assert isinstance(batch[key], torch.Tensor)\n",
        "                batch[key] = batch[key].to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            model_output = model(batch)\n",
        "            batch_metrics = compute_metrics(model_output['all_scores'], model_output['positive_scores'])\n",
        "        for key, values in batch_metrics.items():\n",
        "            eval_metrics[key].extend(values)\n",
        "\n",
        "        if num_batches is not None and idx + 1 >= num_batches:\n",
        "            break\n",
        "\n",
        "    for key, values in eval_metrics.items():\n",
        "        eval_metrics[key] = np.mean(values)\n",
        "\n",
        "    return eval_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw--Hmi6fjjZ"
      },
      "source": [
        "## üîÅ –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JMC0jMAfjjZ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(\n",
        "        train_dataloader: DataLoader,\n",
        "        valid_dataloader: DataLoader,\n",
        "        model: torch.nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        num_epochs: int | None = None,\n",
        "        device: str = 'cpu',\n",
        "        num_valid_batches: Optional[int] = None\n",
        "    ) -> torch.nn.Module:\n",
        "    step_num = 0\n",
        "    epoch_num = 0\n",
        "\n",
        "    best_checkpoint = None\n",
        "    best_metric_name = 'dcg@1000'\n",
        "    best_metric_value = float('-inf')\n",
        "\n",
        "    while num_epochs is None or epoch_num < num_epochs:\n",
        "        print(f'Start epoch {epoch_num + 1}')\n",
        "        running_loss = []\n",
        "\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            model.train()\n",
        "\n",
        "            for key in batch:\n",
        "                if isinstance(batch[key], dict):\n",
        "                    for sub_key in batch[key]:\n",
        "                        batch[key][sub_key] = batch[key][sub_key].to(device)\n",
        "                else:\n",
        "                    assert isinstance(batch[key], torch.Tensor)\n",
        "                    batch[key] = batch[key].to(device)\n",
        "\n",
        "            loss = model(batch)['loss']\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            step_num += 1\n",
        "\n",
        "            running_loss.append(loss.item())\n",
        "\n",
        "        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é\n",
        "        valid_metrics = evaluation(valid_dataloader, model, device, num_valid_batches)\n",
        "\n",
        "        if best_metric_value is None or best_metric_value < valid_metrics[best_metric_name]:\n",
        "            best_metric_value = valid_metrics[best_metric_name]\n",
        "            best_checkpoint = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "        msgs = []\n",
        "        for metric_name, metrinc_value in valid_metrics.items():\n",
        "            msgs.append(f'{metric_name}: {round(metrinc_value, 5)}')\n",
        "        msg = ', '.join(msgs)\n",
        "        print(msg)\n",
        "\n",
        "        # –ü—Ä–æ–≥–æ–Ω—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ —ç–≤–∞–ª\n",
        "        print(f'–°—Ä–µ–¥–Ω–∏–π –ª–æ—Å—Å –Ω–∞ —ç–ø–æ—Ö–µ #{epoch_num + 1}: {round(np.mean(running_loss), 5)}')\n",
        "\n",
        "        epoch_num += 1\n",
        "\n",
        "    print('–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!')\n",
        "\n",
        "    return best_checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn_BUqnQfjjZ"
      },
      "source": [
        "## üèÅ –í—Å–µ –≥–æ—Ç–æ–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UanC70x9fjjZ"
      },
      "source": [
        "1Ô∏è‚É£ –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = YambdaDataset(\n",
        "    dataframe=train_data,\n",
        "    max_seq_len=MAX_SEQ_LEN\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        "    prefetch_factor=4,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "5-BbvO4DcAQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = YambdaDataset(\n",
        "  dataframe=valid_data,\n",
        "  max_seq_len=MAX_SEQ_LEN\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=8,\n",
        "    prefetch_factor=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "del valid_dataset"
      ],
      "metadata": {
        "id": "BmmO725-cF9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dl8ADMOfjjZ"
      },
      "outputs": [],
      "source": [
        "eval_dataset = YambdaDataset(\n",
        "    dataframe=eval_data,\n",
        "    max_seq_len=MAX_SEQ_LEN\n",
        "  )\n",
        "eval_dataloader = DataLoader(\n",
        "    dataset=eval_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=8,\n",
        "    prefetch_factor=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "del eval_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cupZrWKrfjjZ"
      },
      "source": [
        "2Ô∏è‚É£ –û–±—É—á–∞–µ–º `SASRecReal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WZcnsmbfjjZ"
      },
      "outputs": [],
      "source": [
        "model_real = SASRecReal(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    )\n",
        ").to(DEVICE)\n",
        "optimizer_real = torch.optim.Adam(params=model_real.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_real = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_real,\n",
        "    optimizer=optimizer_real,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2KBYEIBfjjZ"
      },
      "source": [
        "3Ô∏è‚É£ –û–±—É—á–∞–µ–º `SASRecInBatch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "burfluTefjjZ"
      },
      "outputs": [],
      "source": [
        "model_in_batch = SASRecInBatch(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    ),\n",
        "    num_negatives=TRAIN_BATCH_SIZE\n",
        ").to(DEVICE)\n",
        "optimizer_in_batch = torch.optim.Adam(params=model_in_batch.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_in_batch = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_in_batch,\n",
        "    optimizer=optimizer_in_batch,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDsrrxt2fjjZ"
      },
      "source": [
        "4Ô∏è‚É£ –û–±—É—á–∞–µ–º `SASRecInBatchWithLogQ`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XECzSR7dfjjZ"
      },
      "outputs": [],
      "source": [
        "item_freqs = torch.zeros(len(item_mapping), dtype=torch.float32)\n",
        "\n",
        "item_statistics, num_labels = compute_item_statistics(train_dataset)\n",
        "for key, val in item_statistics.items():\n",
        "    item_freqs[key] = val / num_labels\n",
        "    assert 0 <= item_freqs[key] < 1.0\n",
        "\n",
        "model_inbatch_logq = SASRecInBatchWithLogQ(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    ),\n",
        "    num_negatives=TRAIN_BATCH_SIZE,\n",
        "    item_freqs=item_freqs\n",
        ").to(DEVICE)\n",
        "optimizer_inbatch_logq = torch.optim.Adam(params=model_inbatch_logq.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_inbatch_logq = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_inbatch_logq,\n",
        "    optimizer=optimizer_inbatch_logq,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOhXysIYfjjZ"
      },
      "source": [
        "# Task 7. –ü–æ–±–∏—Ç—å –ø–æ—Ä–æ–≥–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ (1 –±–∞–ª–ª)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmJaplVefjjZ"
      },
      "source": [
        "1Ô∏è‚É£ –ò–∑–º–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–µ –¥–ª—è `SASRecReal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcmJplYwfjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_real_quality():\n",
        "    model_real.load_state_dict(best_checkpoint_real)\n",
        "    eval_metrics = evaluation(eval_dataloader, model_real, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.0017,\n",
        "        'dcg@100': 0.006,\n",
        "        'dcg@1000': 0.032,\n",
        "        'hitrate@10': 0.0035,\n",
        "        'hitrate@100': 0.027,\n",
        "        'hitrate@1000': 0.23\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'‚ùå {metric_name}: {actual} < {threshold}'\n",
        "        print(f'‚úÖ {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\n‚úÖ test_model_real_quality: OK')\n",
        "\n",
        "test_model_real_quality()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1k2dZMJfjjZ"
      },
      "source": [
        "2Ô∏è‚É£ –ò–∑–º–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–µ –¥–ª—è `SASRecInBatch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdr6ZgV7fjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_in_batch_quality():\n",
        "    model_in_batch.load_state_dict(best_checkpoint_in_batch)\n",
        "    eval_metrics = evaluation(eval_dataloader, model_in_batch, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.007,\n",
        "        'dcg@100': 0.015,\n",
        "        'dcg@1000': 0.034,\n",
        "        'hitrate@10': 0.012,\n",
        "        'hitrate@100': 0.059,\n",
        "        'hitrate@1000': 0.23\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'‚ùå {metric_name}: {actual} < {threshold}'\n",
        "        print(f'‚úÖ {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\n‚úÖ test_model_in_batch_quality: OK')\n",
        "\n",
        "test_model_in_batch_quality()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BivKLlo8fjjZ"
      },
      "source": [
        "3Ô∏è‚É£ –ò–∑–º–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–µ –¥–ª—è `SASRecInBatchWithLogq`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8fXEIydfjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_in_batch_logq_quality():\n",
        "    model_inbatch_logq.load_state_dict(best_checkpoint_inbatch_logq)\n",
        "    eval_metrics = evaluation(eval_dataloader, model_inbatch_logq, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.007,\n",
        "        'dcg@100': 0.015,\n",
        "        'dcg@1000': 0.035,\n",
        "        'hitrate@10': 0.013,\n",
        "        'hitrate@100': 0.059,\n",
        "        'hitrate@1000': 0.23\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'‚ùå {metric_name}: {actual} < {threshold}'\n",
        "        print(f'‚úÖ {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\n‚úÖ test_model_in_batch_logq_quality: OK')\n",
        "\n",
        "test_model_in_batch_logq_quality()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtILpQlHfjjZ"
      },
      "source": [
        "# üß† –ù–µ–º–Ω–æ–≥–æ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã\n",
        "\n",
        "–°—Ç–∞—Ç—å–∏ –∏–∑ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏:\n",
        "1. [PinnerFormer: Sequence Modeling for User Representation at Pinterest](https://arxiv.org/pdf/2205.04507)\n",
        "1. [Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations](https://arxiv.org/pdf/2402.17152v1)\n",
        "1. [Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations](https://arxiv.org/pdf/2306.08121)\n",
        "1. [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/)\n",
        "1. [Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval](https://arxiv.org/abs/2507.09331)\n",
        "\n",
        "\n",
        "–ü—Ä–æ —Ç–æ, –∫–∞–∫ –Ω–∞–¥–æ –∏ –Ω–µ –Ω–∞–¥–æ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å—Å—è:\n",
        "1. [A Critical Study on Data Leakage in Recommender System Offline Evaluation](https://dl.acm.org/doi/full/10.1145/3569930)\n",
        "1. [Exploring Data Splitting Strategies for the Evaluation of Recommendation Models](https://arxiv.org/pdf/2007.13237)\n",
        "\n",
        "\n",
        "–°—Ç–∞—Ç—å–∏ –∏–∑ –∞–∫–∞–¥–µ–º–∏–∏:\n",
        "1. [SASRec: Self-Attentive Sequential Recommendation](https://arxiv.org/abs/1808.09781)\n",
        "1. [BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer](https://arxiv.org/abs/1904.06690)\n",
        "1. [A Systematic Review and Replicability Study of BERT4Rec for Sequential Recommendation](https://dl.acm.org/doi/10.1145/3523227.3548487)\n",
        "1. [CL4SRec Contrastive Learning for Sequential Recommendation](https://arxiv.org/abs/2010.14395)\n",
        "1. [DuoRec: Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation](https://arxiv.org/abs/2110.05730)\n",
        "\n",
        "\n",
        "–ü—Ä–æ –∏–Ω—Ñ—Ä—É:\n",
        "1. [Semantic Product Search](https://dl.acm.org/doi/10.1145/3292500.3330759)\n",
        "1. [Monolith: Real Time Recommendation System With Collisionless Embedding Table](https://arxiv.org/pdf/2209.07663)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8y0Fg-OPIFA2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}