{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68oNOYBFLY_x"
   },
   "source": [
    "# `–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏`\n",
    "\n",
    "#### –§–∞–º–∏–ª–∏—è, –∏–º—è: \n",
    "\n",
    "–î–∞—Ç–∞ –≤—ã–¥–∞—á–∏: <span style=\"color:red\">__4 –Ω–æ—è–±—Ä—è__</span>.\n",
    "\n",
    "–î–µ–¥–ª–∞–π–Ω: <span style=\"color:red\">__18 –Ω–æ—è–±—Ä—è 23:59__</span>.\n",
    "\n",
    "–°—Ç–æ–∏–º–æ—Å—Ç—å: __10 –±–∞–ª–ª–æ–≤__ (–æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –∑–∞–¥–∞–Ω–∏–π) + __2.05 –±–∞–ª–ª–∞__ (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è).\n",
    "\n",
    "<span style=\"color:red\">__–í –Ω–æ—É—Ç–±—É–∫–µ –≤—Å–µ –∫–ª–µ—Ç–∫–∏ –¥–æ–ª–∂–Ω—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫ –ø—Ä–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–º –∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏.__</span>\n",
    "\n",
    "#### `–ú–æ—Å–∫–≤–∞, 2025`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sz1i68n_LY_y"
   },
   "source": [
    "**–ü–ª–∞–Ω –∑–∞–¥–∞–Ω–∏—è:** –ø–∏—à–µ–º —Å–≤–æ—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –µ—ë –Ω–∞ SwissRoll-–∞—Ö, –¥–∞–ª–µ–µ –∑–∞–ø—É—Å–∫–∞–µ–º –µ—ë –Ω–∞ MNIST. \n",
    "\n",
    "**–¶–µ–ª—å –∑–∞–¥–∞–Ω–∏—è:** —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏, —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ —Ñ–æ—Ä–º—É–ª–∞—Ö. –ü—Ä–∏ —ç—Ç–æ–º –ø—Ä–æ–±–ª–µ–º —Å –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π –ø–æ—á—Ç–∏ –±—ã—Ç—å –Ω–µ –¥–æ–ª–∂–Ω–æ. \n",
    "\n",
    "**–§–æ—Ä–º–∞—Ç:** –¥–æ–∑–∞–ø–æ–ª–Ω–∏—Ç—å ```todo``` –∏ –Ω–∞–ø–∏—Å–∞—Ç—å –æ—Ç—á—ë—Ç (–±–µ–∑ –æ—Ç—á—ë—Ç–∞ 0 –±–∞–ª–ª–æ–≤ –∑–∞ –¥–∑)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (1 –±–∞–ª–ª)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –≤–∞–º –Ω—É–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å –ø–æ–º–æ—â—å—é ```wandb``` –∏–ª–∏ –¥—Ä—É–≥–æ–≥–æ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞.\n",
    "\n",
    "–ß—Ç–æ –º–æ–∂–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å: –æ—Å–Ω–æ–≤–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (lr, —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤, —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–∏–∏ –∏ —Ç–¥ –∏ —Ç–ø), –∑–Ω–∞—á–µ–Ω–∏—è –ª–æ—Å—Å–∞, –Ω–æ—Ä–º—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤,  –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, ... ‚Äî –≤ –æ–±—â–µ–º, –≤—Å–µ, —á—Ç–æ –ø–æ–ª—É—á–∏—Ç—Å—è –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcHHLrnuLY_0"
   },
   "source": [
    "## –ò–º–ø–æ—Ä—Ç—ã –∏ SwissRoll-—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCEuXFYOV-Fy"
   },
   "outputs": [],
   "source": [
    "!wget --quiet --show-progress \"https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall24/homework04/utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcjQMkRkLY_1"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEZ1oA4BLY_2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbi3yqCBWHT5"
   },
   "outputs": [],
   "source": [
    "SEED = 777\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NeWUCL0LY_3"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles, make_swiss_roll\n",
    "\n",
    "\n",
    "def make_swiss_dataset(num_samples):\n",
    "    X0, _ = make_swiss_roll(num_samples // 2, noise=0.3, random_state=0)\n",
    "    X1, _ = make_swiss_roll(num_samples // 2, noise=0.3, random_state=0)\n",
    "    X0 = X0[:, [0, 2]]\n",
    "    X1 = X1[:, [0, 2]]\n",
    "    X1 = -X1\n",
    "    X, y = shuffle(\n",
    "        np.concatenate([X0, X1], axis=0),\n",
    "        np.concatenate([np.zeros(len(X0)), np.ones(len(X1))], axis=0),\n",
    "        random_state=0,\n",
    "    )\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = make_swiss_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auZANvzMLY_5"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uncDovU4LY_6"
   },
   "source": [
    "## DDPM (7 –±–∞–ª–ª–æ–≤)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWqy7MvWLY_8"
   },
   "source": [
    "–í –¥–∞–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –Ω–∞–ø–∏—Å–∞—Ç—å —Å–æ–±—Å—Ç–µ–≤–Ω–Ω—É—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (DDPM) –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—ë –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –≤—ã—à–µ.\n",
    "\n",
    "### –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ\n",
    "\n",
    "–ù–∞–ø–æ–º–Ω–∏–º, —á—Ç–æ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –ø—Ä—è–º–æ–≥–æ –∏ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞. –ü—Ä—è–º–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–∫ –∞–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ $q(x_{1:T}|x_0)$. –≠—Ç–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–∫–∂–µ —è–≤–ª—è–µ—Ç—Å—è –ú–∞—Ä–∫–æ–≤—Å–∫–æ–π —Ü–µ–ø–æ—á–∫–æ–π, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º –∫ –¥–∞–Ω–Ω–æ–º—É –Ω–∞—á–∞–ª—å–Ω–æ–º—É –æ–±—ä–µ–∫—Ç—É $x_0$. –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ —à—É–º –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å —Ä–∞–∑–ª–∏—á–Ω–æ–π –º–∞–≥–Ω–∏—Ç—É–¥–æ–π, –∫–æ—Ç–æ—Ä–∞—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º –¥–∏—Å–ø–µ—Ä—Å–∏–π\n",
    " $\\{\\beta_1, ... \\beta_T\\}$. –ü—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –≤—ã–±–æ—Ä–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –≤ –ø—Ä–µ–¥–µ–ª–µ –ø–æ —á–∏—Å–ª—É —à–∞–≥–æ–≤ $T$ –º—ã –¥–æ–ª–∂–Ω—ã —Å–æ–π—Ç–∏—Å—å –∫ —à—É–º—É –∏–∑ $\\mathcal{N}(0, I)$. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π $q$ –±–µ—Ä—É—Ç –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:\n",
    "$$\n",
    " q(x_t | x_{t - 1}) := \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t}x_{t - 1}, \\beta_tI), \\ \\ \\ \\ \\ \\ \\ q(x_{1:T}|x_0) = \\prod_{t = 1}^T q(x_t | x_{t - 1})\n",
    "$$\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞. –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å—à—É–º–ª—è–µ—Ç —à—É–º, –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è –æ–±—ä–µ–∫—Ç –∏–∑ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å - —ç—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å —Å –ª–∞—Ç–µ–Ω—Ç–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –≤–∏–¥–∞ $p_\\theta(x_0) := \\int p_\\theta(x_{0:T}) dx_{1:T}$, –≥–¥–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è $x_1, ..., x_T$ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∑–∞—à—É–º–ª–µ–Ω–Ω—ã–º –æ–±—ä–µ–∫—Ç–∞–º, a $x_0$ - –æ–±—ä–µ–∫—Ç –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. –°–æ–≤–º–µ—Å—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ $p_\\theta(x_{0:T})$ –Ω–∞–∑—ã–≤–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—ã–º –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ú–∞—Ä–∫–æ–≤—Å–∫—É—é —Ü–µ–ø–æ—á–∫—É –∏–∑ –≥–∞—É—Å—Å–æ–≤—Å–∫–∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π $p_\\theta(x_{i-1}|x_{i})$:\n",
    "\n",
    "$$\n",
    "p(x_{0:T}) = p(x_0) \\prod_{t = 1}^Tp_{\\theta}(x_{t-1}|x_t) \\ \\ \\ \\ \\ \\ \\ \\ \\ p_\\theta(x_{T})=\\mathcal{N}(x_T | 0, I)\n",
    "$$\n",
    "$$\n",
    "  p_{\\theta}(x_{t - 1}|x_t):= \\mathcal{N}(x_{t - 1}; \\mu_{\\theta}(x_t, t), \\Sigma_{\\theta}(x_t, t))\n",
    "$$\n",
    "\n",
    "–í–µ—Ä–Ω–µ–º—Å—è –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é $q(x_t | x_{t - 1})$.  –î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å $x_t$, –ø—Ä–∏–¥–µ—Ç—Å—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ –ø–æ–ª—É—á–∞—Ç—å $x_1, ..., x_{t - 1}$. –û–¥–Ω–∞–∫–æ —ç—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –±–ª–∞–≥–æ–¥–∞—Ä—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º. –î–ª—è —ç—Ç–æ–≥–æ –æ–±–æ–∑–Ω–∞—á–∏–º $\\alpha_t := 1- \\beta_t$ –∏ $\\bar{\\alpha}_t:= \\prod_{i = 1}^t\\alpha_i$, —Ç–æ–≥–¥–∞\n",
    "$$\n",
    "q(x_t | x_0) = \\mathcal{N}(x_t;\\sqrt{\\bar{\\alpha}_t} x_0, (1-\\bar{\\alpha}_t)I) \\quad \\quad \\quad \\quad \\quad \\quad (1)\n",
    "$$\n",
    "\n",
    "–ó–∞—Ç–µ–º –º–æ–¥–µ–ª—å –º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—è –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–ª–µ–Ω—ã —Å—É–º–º—ã –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –Ω–∏–∂–Ω–µ–π –æ—Ü–µ–Ω–∫–∏ $\\log p_{\\theta}(x_0)$:\n",
    "$$\n",
    "L_{VLB} = \\mathbb{E}_q [\\underbrace{D_\\text{KL}(q(\\mathbf{x}_T |\n",
    "\\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_T))}_{L_T} + + \\sum_{t=2}^T\n",
    "\\underbrace{D_\\text{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t,\n",
    "\\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_{t-1}\n",
    "| \\mathbf{x}_t))}_{L_{t-1}} \\underbrace{- \\log p_\\theta(\\mathbf{x}_0\n",
    "| \\mathbf{x}_1)}_{L_0}\n",
    "$$\n",
    "\n",
    "–î–ª—è –æ–±—É—á–µ–Ω–∏–µ –Ω—É–∂–Ω–æ –ª–∏—à—å –≤—ã–ø–∏—Å–∞—Ç—å $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0), \\tilde{\\beta}_t \\mathbf{I}) $:\n",
    "\n",
    "$$\n",
    "    \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0 \\ \\ \\ \\ \\ \\ (2)\n",
    "$$\n",
    "$$\n",
    "    \\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t  \\quad \\quad \\quad \\quad \\quad \\quad \\quad (3)\n",
    "$$\n",
    "\n",
    "\n",
    "–ó–∞ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç—è–º–∏ —á–∏—Ç–∞–π—Ç–µ —Å—Ç–∞—Ç—å—é [Denoising Diffusion Probabilistic Models (Ho et al. 2020)](https://arxiv.org/abs/2006.11239).\n",
    "\n",
    "–¢–µ–º –Ω–µ –º–µ–Ω–µ–µ –≤ —É–ø–æ–º—è–Ω—É—Ç–æ–π —Å—Ç–∞—Ç—å–µ –±—ã–ª–æ –ø–æ–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –æ–±—É—á–∞—è—Å—å –Ω–∞ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –ª–æ—Å—Å, –ø–æ–ª—É—á–∞—é—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª—É—á—à–µ.  \n",
    "\n",
    "–ò—Ç–∞–∫, –∑–∞–º–µ—Ç–∏–º, —á—Ç–æ\n",
    "$$\n",
    "x_t(x_0, \\epsilon) = \\sqrt{\\bar{\\alpha}_t} x_0 +  \\sqrt{1-\\bar{\\alpha}_t}\\epsilon, \\ \\ \\ \\epsilon \\sim \\mathcal{N}(0, I) \\quad \\quad \\quad \\quad \\quad \\quad \\quad (4)\n",
    "$$\n",
    "\n",
    "–¢–æ–≥–¥–∞ –ø—É—Å–∫–∞–π –Ω–∞—à–∞ –º–æ–¥–µ–ª—å —Å –≤–µ—Å–∞–º–∏ $\\theta$ –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å $\\epsilon$ –∏–∑ —Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ –≤—ã—à–µ, –∞ –∏–º–µ–Ω–Ω–æ –æ–±—É—á–∞—Ç—å—Å—è, –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—è –¥–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å:\n",
    "\n",
    "$$L^{simple}_t = \\mathbb{E}_{x_0, \\epsilon, t}\\bigg[ \\|\\epsilon - \\epsilon_{\\theta}(x_t, t)\\|^2\\bigg]$$\n",
    "\n",
    "–°–º—ã—Å–ª –≤ —Ç–æ–º, —á—Ç–æ KL –º–µ–∂–¥—É –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏ –ø–æ—Ä–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª–µ–Ω –∫–≤–∞–¥—Ä–∞—Ç—É —Ä–∞–∑–Ω–∏—Ü—ã –º–µ–∂–¥—É –∏—Ö —Å—Ä–µ–¥–Ω–∏–º–∏, –∞ —Å—Ä–µ–¥–Ω–∏–µ –≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑—É—é—Ç—Å—è —á–µ—Ä–µ–∑ $\\epsilon$, –ø–æ—ç—Ç–æ–º—É —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç.\n",
    "\n",
    "–ò–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –ª–æ—Å—Å –≤—ã –¥–æ–ª–∂–Ω—ã –±—É–¥–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.\n",
    "\n",
    "\n",
    "–ß—Ç–æ–±—ã —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å (–æ–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å), –Ω–∞–º –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å $\\mu_{\\theta}(x_t, x_0)$ –∏–∑ $\\epsilon_{\\theta}(x_t, t)$. –î–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—É—á–∏—Ç–µ $\\hat{x}_0(\\epsilon_{\\theta}, x_t)$ –∏–∑ —É—Ä–∞–≤–Ω–µ–Ω–∏—è (4) –∏ –ø–æ–¥—Å—Ç–∞–≤—å—Ç–µ –µ–≥–æ –≤ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ (2). –ü–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ _predict_xstart_from_eps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPkC73BJKHse"
   },
   "source": [
    "–ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∑–∞–¥–∞–Ω–∏—é. –ù–∏–∂–µ –±—É–¥—É—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–≤–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤–∞–º –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9gHH9dPLY_-"
   },
   "outputs": [],
   "source": [
    "# some functions you will need\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "# utility function. basically, returns arr[timesteps], where timesteps are indices. (look at class Diffusion)\n",
    "def _extract_into_tensor(arr, timesteps, broadcast_shape):\n",
    "    \"\"\"\n",
    "    Extract values from a 1-D torch tensor for a batch of indices.\n",
    "    :param arr: 1-D torch tensor.\n",
    "    :param timesteps: a tensor of indices into torch array to extract. (shape is [batch_size])\n",
    "    :param broadcast_shape: a larger shape of K dimensions; output shape will be broadcasted to this\n",
    "                            by adding new dimensions of size 1.\n",
    "                            the first dimension of output tensor will be equal to length of timesteps.\n",
    "    :return: a tensor of shape [batch_size, 1, ...] where tensor shape has K dims.\n",
    "    \"\"\"\n",
    "    res = arr.to(device=timesteps.device)[timesteps].float()\n",
    "    while len(res.shape) < len(broadcast_shape):\n",
    "        res = res[..., None]\n",
    "    return res.expand(broadcast_shape)\n",
    "\n",
    "\n",
    "# our beta_t. we use linear scheduler\n",
    "def get_named_beta_schedule(schedule_name, num_diffusion_timesteps):\n",
    "    \"\"\"\n",
    "    Get a pre-defined beta schedule for the given name.\n",
    "    The beta schedule library consists of beta schedules which remain similar\n",
    "    in the limit of num_diffusion_timesteps.\n",
    "    Beta schedules may be added, but should not be removed or changed once\n",
    "    they are committed to maintain backwards compatibility.\n",
    "    \"\"\"\n",
    "    scale = 1000 / num_diffusion_timesteps\n",
    "    beta_start = scale * 0.0001\n",
    "    beta_end = scale * 0.02\n",
    "    if schedule_name == \"linear\":\n",
    "        # Linear schedule from Ho et al, extended to work for any number of\n",
    "        # diffusion steps.\n",
    "        return np.linspace(\n",
    "            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
    "        )\n",
    "    elif schedule_name == \"quad\":\n",
    "        betas = (\n",
    "            torch.linspace(beta_start**0.5, beta_end**0.5, num_diffusion_timesteps) ** 2\n",
    "        )\n",
    "        return betas.numpy()\n",
    "    elif schedule_name == \"sigmoid\":\n",
    "        betas = torch.linspace(-6, 6, num_diffusion_timesteps)\n",
    "        betas = torch.sigmoid(betas) * (beta_end - beta_start) + beta_start\n",
    "        return betas.numpy()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFFqaztHJXTx"
   },
   "source": [
    "### –ö–ª–∞—Å—Å Diffusion (5 –±–∞–ª–ª–æ–≤ –∏–∑ 7 –∑–∞ DDPM)\n",
    "–í–∞–º –Ω—É–∂–Ω–æ –¥–æ–ø–∏—Å–∞—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —á–∞—Å—Ç–∏ –Ω–∏–∂–µ (–ø–æ–º–µ—á–µ–Ω—ã todo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXtIrJyGLZAA",
    "outputId": "68fd6add-3f0e-44ac-af94-b021708b934c"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        betas: np.ndarray, # type: ignore\n",
    "        loss_type: str = \"mse\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Class that simulates Diffusion process. Does not store model or optimizer.\n",
    "        \"\"\"\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        betas = torch.from_numpy(betas).double()\n",
    "        self.betas = betas\n",
    "        assert len(betas.shape) == 1, \"betas must be 1-D\"\n",
    "        assert (betas > 0).all() and (betas <= 1).all()\n",
    "\n",
    "        self.num_timesteps = int(betas.shape[0])\n",
    "\n",
    "        alphas = # todo\n",
    "        self.alphas_cumprod = # todo\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0]), self.alphas_cumprod[:-1]], dim=0)  # \\bar\\alpha_{t-1}\n",
    "        self.alphas_cumprod_next = torch.cat([self.alphas_cumprod[1:], torch.tensor([0.0]), ], dim=0)  # \\bar\\alpha_{t+1}\n",
    "        assert self.alphas_cumprod_prev.shape == (self.num_timesteps,)\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1})\n",
    "        self.sqrt_alphas_cumprod = self.alphas_cumprod.sqrt()\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        self.log_one_minus_alphas_cumprod = torch.log(1.0 - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod - 1)\n",
    "\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = # todo, var from (3)\n",
    "\n",
    "        # log calculation clipped because posterior variance is 0.\n",
    "        self.posterior_log_variance_clipped = torch.log(\n",
    "            torch.cat([self.posterior_variance[1:2], self.posterior_variance[1:]], dim=0)\n",
    "        )\n",
    "        self.posterior_mean_coef1 = # todo, coef of xt from (2)\n",
    "        self.posterior_mean_coef2 = # todo, coef of x0 from (2)\n",
    "\n",
    "    def q_mean_variance(self, x0, t):\n",
    "        \"\"\"\n",
    "        Get mean and variance of distribution q(x_t | x_0) for specific x_0 and t. Use equation (1).\n",
    "        \"\"\"\n",
    "\n",
    "        mean = # todo ; use _extract_into_tensor(*, t, x0.shape) function here and below for getting specific value from *alphas* array\n",
    "        variance = # todo\n",
    "        log_variance = # todo\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def q_posterior_mean_variance(self, x_start, x_t, t):\n",
    "        \"\"\"\n",
    "        Compute mean and variance of diffusion posterior q(x_{t-1} | x_t, x_0) for specific x_t and t.\n",
    "        Use equation (2) and (3).\n",
    "\n",
    "        x_start is x_0 in formulas\n",
    "        \"\"\"\n",
    "        assert x_start.shape == x_t.shape\n",
    "        posterior_mean = # todo\n",
    "        posterior_variance = _extract_into_tensor(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = _extract_into_tensor(\n",
    "            self.posterior_log_variance_clipped, t, x_t.shape\n",
    "        )\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        \"\"\"\n",
    "        Diffuse data for a given number of diffusion steps.\n",
    "        Sample from q(x_t | x_0) use (4).\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        return # todo\n",
    "\n",
    "    def _predict_xstart_from_eps(self, x_t, t, eps):\n",
    "        \"\"\"\n",
    "        Get \\hat{x0} from epsilon_{theta}. Use equation (4) to derive it.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def p_mean_variance(self, model_output, x, t):\n",
    "        \"\"\"\n",
    "        Apply model to get p(x_{t-1} | x_t). Use Equation (2) and plug in \\hat{x}_0;\n",
    "        \"\"\"\n",
    "        model_variance = torch.cat([self.posterior_variance[1:2], self.betas[1:]], dim=0)\n",
    "        model_log_variance = torch.log(model_variance)\n",
    "        model_variance = _extract_into_tensor(model_variance, t, x.shape)\n",
    "        model_log_variance = _extract_into_tensor(model_log_variance, t, x.shape)\n",
    "\n",
    "        pred_xstart = self._predict_xstart_from_eps(x, t, model_output)\n",
    "\n",
    "        model_mean = # todo ; don't forget to extract specific values from posterior_mean_coef1 and posterior_mean_coef2 using _extract_into_tensor\n",
    "\n",
    "        return {\n",
    "            \"mean\": model_mean,\n",
    "            \"variance\": model_variance,\n",
    "            \"log_variance\": model_log_variance,\n",
    "            \"pred_xstart\": pred_xstart,\n",
    "        }\n",
    "\n",
    "    def p_sample(self, model_output, x, t):\n",
    "        \"\"\"\n",
    "        Sample from p(x_{t-1} | x_t).\n",
    "        \"\"\"\n",
    "        out = # todo; get mean, variance of p(xt-1|xt)\n",
    "        noise = torch.randn_like(x)\n",
    "        nonzero_mask = (\n",
    "            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))\n",
    "        )  # no noise when t == 0\n",
    "\n",
    "\n",
    "        sample = out[\"mean\"] + nonzero_mask * torch.exp(0.5 * out[\"log_variance\"]) * noise\n",
    "        return {\"sample\": sample}\n",
    "\n",
    "    def p_sample_loop(self, model, shape, y_dist):\n",
    "        \"\"\"\n",
    "        Samples a batch=shape[0] using diffusion model.\n",
    "        \"\"\"\n",
    "\n",
    "        x = torch.randn(*shape, device=model.device)\n",
    "        indices = list(range(self.num_timesteps))[::-1]\n",
    "\n",
    "        y = torch.multinomial(\n",
    "            y_dist,\n",
    "            num_samples=shape[0],\n",
    "            replacement=True\n",
    "        ).to(x.device)\n",
    "\n",
    "        for i in tqdm(indices):\n",
    "            t = torch.tensor([i] * shape[0], device=x.device)\n",
    "            with torch.no_grad():\n",
    "                model_output = model(x, t, y)\n",
    "                out = self.p_sample(\n",
    "                    model_output,\n",
    "                    x,\n",
    "                    t\n",
    "                )\n",
    "                x = out[\"sample\"]\n",
    "        return x, y\n",
    "\n",
    "    def train_loss(self, model, x0, y):\n",
    "        \"\"\"\n",
    "        Calculates loss L^{simple}_t for the given model, x0.\n",
    "        \"\"\"\n",
    "        t = torch.randint(0, self.num_timesteps, size=(x0.size(0),), device=x0.device)\n",
    "        noise = # todo: sample tensor of shape x0 with noise (from std normal distribution)\n",
    "        x_t = # todo use q_sample() to get diffused samples with specific noise\n",
    "        model_output = # todo; predict sampled noise from (x_t, t, y)\n",
    "        if self.loss_type == 'mse':\n",
    "            loss = # todo; compute mse loss\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ4Mi-mlLZAB"
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "\n",
    "diffusion = Diffusion(betas=get_named_beta_schedule(\"linear\", T), loss_type=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dias6xFZEeSH"
   },
   "outputs": [],
   "source": [
    "# Check some coeffs (beta version asserts, but they should help)\n",
    "assert torch.allclose(\n",
    "    diffusion.alphas_cumprod[[0, 5, 60]],\n",
    "    torch.DoubleTensor([0.999, 0.9644, 0.0202]),\n",
    "    rtol=1e-4,\n",
    "    atol=1e-4,\n",
    ")\n",
    "\n",
    "\n",
    "assert torch.allclose(\n",
    "    diffusion.posterior_mean_coef2[[2, 20, 60]],\n",
    "    torch.DoubleTensor([0.5562, 0.0928, 0.0188]),\n",
    "    rtol=1e-4,\n",
    "    atol=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6uoyhHtEeSI"
   },
   "outputs": [],
   "source": [
    "# Check some methods (beta version asserts, but they should help)\n",
    "assert torch.allclose(\n",
    "    diffusion.q_sample(\n",
    "        x_start=torch.FloatTensor([[0.1, -0.2, 0.3]]),\n",
    "        t=torch.LongTensor([[42]]),\n",
    "        noise=torch.FloatTensor([[0.01, -0.02, 0.1]]),\n",
    "    )[0],\n",
    "    torch.FloatTensor([[0.0476, -0.0953, 0.2075]]),\n",
    "    rtol=1e-4,\n",
    "    atol=1e-4,\n",
    ")\n",
    "\n",
    "assert torch.allclose(\n",
    "    diffusion.p_mean_variance(\n",
    "        model_output=torch.FloatTensor([[0.01, -0.21, 0.32]]),\n",
    "        x=torch.FloatTensor([[0.01, -0.02, 0.1]]),\n",
    "        t=torch.LongTensor([[42]]),\n",
    "    )[\"mean\"][0],\n",
    "    torch.FloatTensor([[0.0095, -0.0006, 0.0736]]),\n",
    "    rtol=1e-4,\n",
    "    atol=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvZykOR5LZAB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_noising(diffusion, X, y):\n",
    "    fig, axs = plt.subplots(1, 10, figsize=(40, 5))\n",
    "    for i, t in enumerate(range(0, diffusion.num_timesteps, 10)):\n",
    "        x = diffusion.q_sample(\n",
    "            x_start=torch.from_numpy(X),\n",
    "            t=torch.ones_like(torch.from_numpy(y)).long() * t,\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(x=x[:, 0], y=x[:, 1], hue=y, ax=axs[i])\n",
    "        axs[i].set(title=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKnZBT70LZAC"
   },
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –∑–∞—à—É–º–ª—è—é—Ç—Å—è –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º $t$. –ö–∞–∫ –¥—É–º–∞–µ—Ç–µ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ $T = 100$ –∏–ª–∏ –Ω–∞–¥–æ —É–≤–µ–ª–∏—á–∏—Ç—å? –ö–∞–∫ –º–æ–∂–Ω–æ –ø–æ–Ω—è—Ç—å, —Å–∫–æ–ª—å–∫–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ? (–Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AfcaKEeLZAC"
   },
   "outputs": [],
   "source": [
    "show_noising(diffusion, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c22OaGgtLZAE"
   },
   "source": [
    "### –ú–æ–¥–µ–ª—å (1 –±–∞–ª–ª –∏–∑ 7 –∑–∞ DDPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGRw1RGKLZAE"
   },
   "source": [
    "–¢—É—Ç –º—ã —Ä–µ–∞–ª–∏–∑—É–µ–º –º–æ–¥–µ–ª—å —Å –≤–µ—Å–∞–º–∏ $\\theta$, –∫–æ—Ç–æ—Ä–∞—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑—É–µ—Ç –æ–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å. –ú–æ–¥–µ–ª—å –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–ª–æ–∂–Ω–æ–π –∏ –±–æ–ª—å—à–æ–π. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–ª—å–∫–æ –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ–µ–≤. –ù–µ –∑–∞–±—É–¥—å—Ç–µ —É—á–µ—Å—Ç—å –∫–ª–∞—Å—Å—ã $y$ –∏ —à–∞–≥–∏ $t$. –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —à—É–º $\\epsilon: \\epsilon_{\\theta}(x_t, t, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSYC7KmvLZAF"
   },
   "outputs": [],
   "source": [
    "class DiffModel(nn.Module):\n",
    "    def __init__(self, d_in, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden = 128\n",
    "\n",
    "        # one may use a simple model that projects x and t into space of size self.hidden\n",
    "        # transforms y label into space of size self.hidden (nn.Embedding), sum all the vectors and postprocess it with MLP\n",
    "        # try SiLU?? stonks\n",
    "\n",
    "        self.x_proj = # todo\n",
    "        self.t_proj = # todo\n",
    "        self.y_embed = # todo\n",
    "        self.layers = # todo\n",
    "\n",
    "    def forward(self, x, t, y):\n",
    "        '''\n",
    "        :x input, e.g. images\n",
    "        :t 1d torch.LongTensor of timesteps\n",
    "        :y 1d torch.LongTensor of class labels\n",
    "        '''\n",
    "        # todo\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnIuhHwTLZAG"
   },
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (1 –±–∞–ª–ª –∏–∑ 7 –∑–∞ DDPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfjHOndQLZAG"
   },
   "source": [
    "–ù–∞–∫–æ–Ω–µ—Ü, –æ–±—É—á–∏–º –Ω–∞—à—É –º–æ–¥–µ–ª—å. –ù–∏–∂–µ –∑–∞ –≤–∞—Å –Ω–∞–ø–∏—Å–∞–Ω –∫–ª–∞—Å—Å `Trainer`, –∫–æ—Ç–æ—Ä—ã–π —Ö—Ä–∞–Ω–∏—Ç –º–æ–¥–µ–ª—å, –¥–∏—Ñ—Ñ—É–∑–∏—é –∏ –æ–ø—Ç–∏–º–∞–π–∑–µ—Ä. –í–∞–º –Ω–∞–¥–æ –ª–∏—à—å –¥–æ–ø–∏—Å–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `_run_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hl6OajqTLZAG"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        diffusion: Diffusion,\n",
    "        model: nn.Module,\n",
    "        train_iter,  # iterable that yields (x, y)\n",
    "        lr: float,\n",
    "        weight_decay: float,\n",
    "        steps: int,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        self.diffusion = diffusion\n",
    "\n",
    "        self.train_iter = train_iter\n",
    "        self.steps = steps\n",
    "        self.init_lr = lr\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.device = device\n",
    "        self.log_every = 100\n",
    "        self.print_every = 500\n",
    "\n",
    "    def _anneal_lr(self, step: int):\n",
    "        \"\"\"\n",
    "        Performs annealing of lr.\n",
    "        \"\"\"\n",
    "\n",
    "        frac_done = step / self.steps\n",
    "        lr = self.init_lr * (1 - frac_done)\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "    def _run_step(self, x: torch.FloatTensor, y: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        A single training step.\n",
    "        Calculates loss (using Diffusion.train_loss() )for a single batch.\n",
    "        Then performs a single optimizer step (don't forget to zero grad) and returns loss.\n",
    "        \"\"\"\n",
    "        # todo\n",
    "        # zero_grad, calc loss, backw\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def run_loop(self):\n",
    "        \"\"\"\n",
    "        Training loop.\n",
    "        \"\"\"\n",
    "        step = 0\n",
    "        curr_loss_gauss = 0.0\n",
    "\n",
    "        curr_count = 0\n",
    "        while step < self.steps:\n",
    "            x, y = next(self.train_iter)\n",
    "            batch_loss = self._run_step(x, y)\n",
    "\n",
    "            self._anneal_lr(step)\n",
    "\n",
    "            curr_count += len(x)\n",
    "            curr_loss_gauss += batch_loss.item() * len(x)\n",
    "\n",
    "            if (step + 1) % self.log_every == 0:\n",
    "                gloss = np.around(curr_loss_gauss / curr_count, 4)\n",
    "                if (step + 1) % self.print_every == 0:\n",
    "                    print(f\"Step {(step + 1)}/{self.steps} Loss: {gloss}\")\n",
    "                curr_count = 0\n",
    "                curr_loss_gauss = 0.0\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOh210qELZAG"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –æ–±–µ—Ä–Ω–µ–º –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –≤ `DataLoader`. –î–ª—è —ç—Ç–æ–≥–æ –∑–∞ –≤–∞—Å –Ω–∞–ø–∏—Å–∞–Ω `FastTensorDataLoader`. –¢–∞–∫–∂–µ —É –Ω–∞—Å –∏–¥–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–µ –ø–æ —ç–ø–æ—Ö–∞–º, –∞ –ø–æ –∏—Ç–µ—Ä–∞—Ü–∏—è–º, –ø–æ—ç—Ç–æ–º—É –Ω–∞–º –Ω—É–∂–µ–Ω \"–±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π\" –∏—Ç–µ—Ä–∞—Ç–æ—Ä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a6yQGSTLZAG"
   },
   "outputs": [],
   "source": [
    "from utils import FastTensorDataLoader\n",
    "\n",
    "\n",
    "def get_data_iter(X: np.ndarray, y: np.ndarray, batch_size: int = 512):\n",
    "    X = torch.from_numpy(X).float()\n",
    "    y = torch.from_numpy(y).long()\n",
    "    dataloader = FastTensorDataLoader(X, y, batch_size=batch_size, shuffle=True)\n",
    "    while True:\n",
    "        yield from dataloader\n",
    "\n",
    "\n",
    "data_iter = get_data_iter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mr-YGEIuLZAH"
   },
   "outputs": [],
   "source": [
    "# you can change hyperparameters\n",
    "model = DiffModel(d_in=2)\n",
    "model.device = torch.device(\"cpu\")  # –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ cpu\n",
    "trainer = Trainer(\n",
    "    diffusion, model, train_iter=data_iter, lr=0.01, weight_decay=0.0, steps=6000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0dtk6JaLZAH"
   },
   "outputs": [],
   "source": [
    "trainer.run_loop()  # < 1min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf5sPAxILZAH"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω–∞—Å—ç–º–ø–ª–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y552va6ELZAH"
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def sample_synthetic(\n",
    "    diffusion: Diffusion,\n",
    "    model: nn.Module,\n",
    "    num_samples: int,\n",
    "    batch: int = 1000,\n",
    "    shape: Tuple = (2,),\n",
    "    y_dist: List[float] = [0.5, 0.5],\n",
    "    ddim: bool = False,\n",
    "):\n",
    "    sample_func = diffusion.p_sample_loop\n",
    "    if ddim:  # for the last task\n",
    "        sample_func = diffusion.ddim_sample\n",
    "    res_x = []\n",
    "    res_y = []\n",
    "    num_sampled = 0\n",
    "    while num_sampled < num_samples:\n",
    "        x, y = diffusion.p_sample_loop(\n",
    "            model, shape=(batch, *shape), y_dist=torch.tensor(y_dist)\n",
    "        )\n",
    "        res_x.append(x.cpu())\n",
    "        res_y.append(y.cpu())\n",
    "        num_sampled += batch\n",
    "\n",
    "    res_x = torch.cat(res_x, dim=0)\n",
    "    res_y = torch.cat(res_y, dim=0)\n",
    "    return res_x[:num_samples], res_y[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCYZQbfILZAI"
   },
   "outputs": [],
   "source": [
    "Xs, ys = sample_synthetic(diffusion, model, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMDKIkc5LZAI"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=Xs[:, 0], y=Xs[:, 1], hue=ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSS_RMuuLZAI"
   },
   "source": [
    "–û—Ü–µ–Ω–∏—Ç–µ –Ω–∞ –≥–ª–∞–∑, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–µ–ø–ª–æ—Ö–æ). –ö–∞–∫ –º–æ–∂–Ω–æ —á–∏—Å–ª–µ–Ω–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∏–º–µ–Ω–Ω–æ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö)?  –ü—É–Ω–∫—Ç –Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoU_XRKCLBQJ"
   },
   "source": [
    "–ü–æ–∫–∞–∂–∏—Ç–µ –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å—à—É–º–ª–µ–Ω–∏—è –∞–Ω–∞–ª–∞–≥–∏—á–Ω–æ —Ç–æ–º—É, –∫–∞–∫ –º—ã —ç—Ç–æ –¥–µ–ª–∞–ª–∏ –¥–ª—è –ø—Ä—è–º–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdA95T6bLKdf"
   },
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_KJR7vLLZAJ"
   },
   "source": [
    "## MNIST (2 –±–∞–ª–ª–∞)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bl6fIqYkLZAJ"
   },
   "source": [
    "–ü–µ—Ä–µ–π–¥—ë–º –∫ –æ–±—É—á–µ–Ω–∏—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ MNIST. –ó–∞ –≤–∞—Å —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏. –í –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ –Ω–∞–¥–æ –ª–∏—à—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ *—Ö–æ—Ä–æ—à–∏–π* —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É—è –∫–ª–∞—Å—Å `Diffusion`, –∞ —Ç–∞–∫–∂–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —à—É–º–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMz3KEuxLC5K"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class InfiniteDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Initialize an iterator over the dataset.\n",
    "        self.dataset_iterator = super().__iter__()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            batch = next(self.dataset_iterator)\n",
    "        except StopIteration:\n",
    "            # Dataset exhausted, use a new fresh iterator.\n",
    "            self.dataset_iterator = super().__iter__()\n",
    "            batch = next(self.dataset_iterator)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFiFelJwLZAK"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import Compose, Lambda, Normalize, ToTensor\n",
    "\n",
    "transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "dataset = MNIST(\"./datasets\", download=True, train=True, transform=transform)\n",
    "loader = InfiniteDataLoader(dataset, 512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ej70iAHKLZAK"
   },
   "outputs": [],
   "source": [
    "def show_images(images, ys, title=\"\"):\n",
    "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
    "\n",
    "    # Converting images to CPU numpy arrays\n",
    "    if type(images) is torch.Tensor:\n",
    "        images = images.detach().cpu().numpy()\n",
    "        ys = ys.detach().cpu().numpy()\n",
    "\n",
    "    # Defining number of rows and columns\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    rows = int(len(images) ** (1 / 2))\n",
    "    cols = round(len(images) / rows)\n",
    "\n",
    "    # Populating figure with sub-plots\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            fig.add_subplot(rows, cols, idx + 1)\n",
    "\n",
    "            if idx < len(images):\n",
    "                plt.imshow(images[idx][0], cmap=\"gray\")\n",
    "                plt.title(f\"{int(ys[idx])}\")\n",
    "                plt.tick_params(bottom=False, labelbottom=False)\n",
    "                idx += 1\n",
    "    fig.suptitle(title, fontsize=30)\n",
    "\n",
    "    # Showing the figure\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_first_batch(loader):\n",
    "    for batch in loader:\n",
    "        show_images(batch[0][:16], batch[1][:16], \"Images in the first batch\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvHVOBxKLZAL"
   },
   "outputs": [],
   "source": [
    "show_first_batch(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymS7VXuALZAL"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\n",
    "    f\"Using device: {device}\\t\"\n",
    "    + (f\"{torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"CPU\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6UXgAnbLZAM"
   },
   "outputs": [],
   "source": [
    "from utils import MyUNet\n",
    "\n",
    "model_mnist = MyUNet().to(device)\n",
    "model_mnist.device = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcWdlIb3LZAM"
   },
   "source": [
    "### –°–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —à—É–º–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PlNaBRVLZAM"
   },
   "source": [
    "–ü—Ä–µ–∂–¥–µ —á–µ–º –Ω–∞—á–∞—Ç—å, –ø–æ—Å—Ç—Ä–æ–π—Ç–µ –Ω–∞ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ –≥—Ä–∞—Ñ–∏–∫–∏ $\\sqrt{\\bar{\\alpha_t}}$ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ $t$) –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π (linear, quad, sigmoid). –û–±—ä—è—Å–Ω–∏—Ç–µ, —á–µ–º –æ–Ω–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è. –ß—Ç–æ–±—ã –ª—É—á—à–µ —ç—Ç–æ –ø–æ–Ω—è—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∑–∞—à—É–º–ª–µ–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–æ–∫ (—Ñ—É–Ω–∫—Ü–∏—è `show_noising_mnist`). –°–æ–≤–µ—Ç—É—é –≤—ã–±—Ä–∞—Ç—å $T = 1000$ (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä, –µ—Å–ª–∏ –¥–æ–º–µ–Ω -- –∫–∞—Ä—Ç–∏–Ω–∫–∏). –î–∞–Ω–Ω—ã–π –ø—É–Ω–∫—Ç –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rt5z549FLZAN"
   },
   "outputs": [],
   "source": [
    "def get_alpha_bar(betas):\n",
    "    # todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpRDr6f5LZAN"
   },
   "outputs": [],
   "source": [
    "ts = range(1000)\n",
    "\n",
    "# your plots here\n",
    "\n",
    "plt.legend([\"linear\", \"quad\", \"sigmoid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RTnAXNmLZAN"
   },
   "outputs": [],
   "source": [
    "# almost the same as in the task with SwissRolls\n",
    "\n",
    "def show_noising_mnist(diffusion, img):\n",
    "   # todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OklbFbrLZAN"
   },
   "outputs": [],
   "source": [
    "for sch in [\"linear\", \"quad\", \"sigmoid\"]:\n",
    "    diffusion_temp = Diffusion(\n",
    "        betas=get_named_beta_schedule(sch, 1000), loss_type=\"mse\"\n",
    "    )\n",
    "    show_noising_mnist(diffusion_temp, dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWJNsaX7LZAO"
   },
   "source": [
    "### –û–±—É—á–∞–µ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1ywU_RGLZAO"
   },
   "outputs": [],
   "source": [
    "scheduler = # choose your pokemon\n",
    "\n",
    "diffusion_mnist = Diffusion(\n",
    "    betas=get_named_beta_schedule(scheduler, 1000),\n",
    "    loss_type=\"mse\"\n",
    ")\n",
    "\n",
    "# feel free to change hyperaparameters\n",
    "\n",
    "trainer_mnist = Trainer(\n",
    "    diffusion_mnist,\n",
    "    model_mnist,\n",
    "    train_iter=loader,\n",
    "    lr=0.001,\n",
    "    steps=1000,\n",
    "    weight_decay=0.0,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9iksepULZAP"
   },
   "outputs": [],
   "source": [
    "trainer_mnist.run_loop()  # <15min on 2080Ti for the author's solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ge0P-sUwLZAP"
   },
   "outputs": [],
   "source": [
    "Xs, ys = sample_synthetic(\n",
    "    diffusion_mnist,\n",
    "    model_mnist,\n",
    "    num_samples=16,\n",
    "    batch=16,\n",
    "    shape=(1, 28, 28),\n",
    "    y_dist=[0.1 for _ in range(10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlmccDpsLZAW"
   },
   "outputs": [],
   "source": [
    "show_images(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a33pasGULZAX"
   },
   "source": [
    "–û—Ü–µ–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ë–æ–Ω—É—Å (2 –±–∞–ª–ª)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –æ–±—É—á–∏—Ç–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–∫—É –Ω–∞ —Ü–≤–µ—Ç–Ω–æ–º MNIST. –ü–æ [—Å—Å—ã–ª–∫–µ](https://disk.yandex.ru/d/D_7g3UDaYXK4Lg) –∏–∑ –¥–æ–º–∞—à–∫–∏ —Å –∫—É—Ä—Å–∞ \"–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–∏\" –î–µ–Ω–∏—Å–∞ –†–∞–∫–∏—Ç–∏–Ω–∞ –≤ —Ñ–∞–π–ª–µ HW1-1.ipynb –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∫–ª–∞—Å—Å –¥–ª—è —Ü–≤–µ—Ç–Ω–æ–≥–æ MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Ç—á—ë—Ç\n",
    "```(–±–µ–∑ —ç—Ç–æ–π —á–∞—Å—Ç–∏ 0 –∑–∞ –¥–∑)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–∏—Ç–µ –æ—Ç—á–µ—Ç –ø–æ –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω–æ–π —Ä–∞–±–æ—Ç–µ (—Ç—É—Ç –º–æ–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å –≤—Å–µ, —á—Ç–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ –∫ –¥–æ–º–∞—à–∫–µ –∏ –Ω–µ –∑–∞–±—É–¥—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ wandb –∏–ª–∏ –Ω–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π —Å–µ—Ä–≤–∏—Å).\n",
    "\n",
    "```[–û—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç—É—Ç]```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Å—Ç–∞–≤—å—Ç–µ –ª—é–±–æ–π –º–µ–º –∏–ª–∏ –∞–Ω–µ–∫–¥–æ—Ç, —á—Ç–æ–±—ã –ø–æ–¥–Ω—è—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä—è—é—â–µ–º—É (–µ—Å–ª–∏ –±—É–¥–µ—Ç —Å–º–µ—à–Ω–æ–π, —Ç–æ –±–æ–Ω—É—Å ```+0.05 –±–∞–ª–ª–∞```)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a06af253165e97d0c1e75e8bf6d3252013856f30b8177e11b02d3fa36c37333d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
